{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Application\n",
    "output-file: application_class.html\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp classes.DomoApplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import httpx\n",
    "\n",
    "import domolibrary.routes.job as job_routes\n",
    "import domolibrary.routes.application as application_routes\n",
    "import domolibrary.classes.DomoJob as dmdj\n",
    "import domolibrary.utils.DictDot as util_dd\n",
    "import domolibrary.client.DomoAuth as dmda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are applications?\n",
    "Applications tend to be tooling that domo implemented on the executor framework or extensions to domo products that originated as custom apps that have been fully integrated into the UI.\n",
    "\n",
    "For example Publish started out as a 3rd party app that was later integrated into domo as an App, and then later received dedicated API paths.\n",
    "\n",
    "Similarly Remote DomoStats / Observability metrics started out as 3rd party scripting, which was later integrated into Domo's \"Executor Framework\" an internal framework for managing java / lambda functions, now defined under the application APIs.\n",
    "\n",
    "Note, pieces of the executor framework has slowly been morphed and adapted into CodeEngine and exposed to end users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DomoApplication:\n",
    "    id: str\n",
    "    customer_id: str = None\n",
    "    name: str = None\n",
    "    description: str = None\n",
    "    version: str = None\n",
    "    execution_class: str = None\n",
    "    grants: [str] = None\n",
    "    jobs: [dmdj.DomoJob] = field(default=None)\n",
    "    jobs_schedule: pd.DataFrame = field(default=None, repr=False)\n",
    "    auth: dmda.DomoFullAuth = field(repr=False, default=None)\n",
    "\n",
    "    @classmethod\n",
    "    def _from_json(cls, obj, auth: dmda.DomoFullAuth = None):\n",
    "        dd = util_dd.DictDot(obj)\n",
    "\n",
    "        return cls(\n",
    "            id=dd.applicationId,\n",
    "            customer_id=dd.customerId,\n",
    "            name=dd.name,\n",
    "            description=dd.description,\n",
    "            version=dd.version,\n",
    "            execution_class=dd.executionClass,\n",
    "            grants=dd.authorities,\n",
    "            auth=auth,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    async def get_from_id(cls, auth: dmda.DomoFullAuth, application_id=None):\n",
    "        res = await application_routes.get_application_by_id(\n",
    "            application_id=application_id, auth=auth\n",
    "        )\n",
    "\n",
    "        if res.status == 200:\n",
    "            return cls._from_json(obj=res.response, auth=auth)\n",
    "\n",
    "    async def get_jobs(\n",
    "        self,\n",
    "        auth: dmda.DomoFullAuth = None,\n",
    "        application_id: str = None,\n",
    "        debug_api: bool = False,\n",
    "        session: Optional[httpx.AsyncClient] = None,\n",
    "        return_raw: bool = False,\n",
    "    ):\n",
    "\n",
    "        res = await job_routes.get_jobs(\n",
    "            auth=auth or self.auth,\n",
    "            application_id=application_id or self.id,\n",
    "            debug_api=debug_api,\n",
    "            session=session,\n",
    "        )\n",
    "        if debug_api:\n",
    "            print(\"Getting Domostats jobs\")\n",
    "\n",
    "        if res.status == 200 and not return_raw:\n",
    "            self.jobs = [dmdj.DomoJob._from_json(job) for job in res.response]\n",
    "            return self.jobs\n",
    "\n",
    "        if res.status == 200 and return_raw:\n",
    "            return res.response\n",
    "\n",
    "    async def get_all_schedules(self, auth: dmda.DomoFullAuth = None):\n",
    "        if not self.jobs and (self.auth or auth):\n",
    "            await self.get_jobs()\n",
    "\n",
    "        elif not self.jobs and not (self.auth or auth):\n",
    "            raise Exception(\"pass a auth object\")\n",
    "\n",
    "        schedules = pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"hour\": trigger.schedule.hour,\n",
    "                    \"minute\": trigger.schedule.minute,\n",
    "                    \"job_id\": job.id,\n",
    "                    \"job_name\": job.name,\n",
    "                    \"trigger_id\": trigger.id,\n",
    "                }\n",
    "                for job in self.jobs\n",
    "                for trigger in job.triggers\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.jobs_schedule = schedules.sort_values(\n",
    "            [\"hour\", \"minute\"], ascending=True\n",
    "        ).reset_index(drop=True)\n",
    "        return self.jobs_schedule\n",
    "\n",
    "    async def find_next_job_schedule(\n",
    "        self, auth: dmda.DomoAuth = None\n",
    "    ) -> dmdj.DomoTrigger_Schedule:\n",
    "        if not isinstance(self.jobs_schedule, pd.DataFrame) and (self.auth or auth):\n",
    "            await self.get_all_schedules()\n",
    "\n",
    "        elif not isinstance(self.jobs_schedule, pd.DataFrame) and not (\n",
    "            self.auth or auth\n",
    "        ):\n",
    "            raise Exception(\"pass a auth object\")\n",
    "\n",
    "        df_all_hours = pd.DataFrame(range(0, 23), columns=[\"hour\"])\n",
    "        df_all_minutes = pd.DataFrame(range(0, 60), columns=[\"minute\"])\n",
    "\n",
    "        df_all_hours[\"tmp\"] = 1\n",
    "        df_all_minutes[\"tmp\"] = 1\n",
    "        df_all = pd.merge(df_all_hours, df_all_minutes, on=\"tmp\").drop(columns=[\"tmp\"])\n",
    "\n",
    "        # get the number of occurencies of each hour and minutes\n",
    "        schedules_grouped = (\n",
    "            self.jobs_schedule.groupby([\"hour\", \"minute\"])\n",
    "            .size()\n",
    "            .reset_index(name=\"cnt_schedule\")\n",
    "        )\n",
    "\n",
    "        # print(schedules_grouped)\n",
    "        # print(df_all)\n",
    "\n",
    "        schedules_interpolated = pd.merge(\n",
    "            df_all, schedules_grouped, how=\"left\", on=[\"hour\", \"minute\"]\n",
    "        )\n",
    "\n",
    "        schedules_interpolated[\"cnt_schedule\"] = schedules_interpolated[\n",
    "            \"cnt_schedule\"\n",
    "        ].fillna(value=0)\n",
    "        schedules_interpolated.sort_values(\n",
    "            [\"cnt_schedule\", \"hour\", \"minute\"], ascending=True, inplace=True\n",
    "        )\n",
    "\n",
    "        schedules_interpolated.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        return dmdj.DomoTrigger_Schedule(\n",
    "            hour=int(schedules_interpolated.loc[0].get(\"hour\")),\n",
    "            minute=int(schedules_interpolated.loc[0].get(\"minute\")),\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

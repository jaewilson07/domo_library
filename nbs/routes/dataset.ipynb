{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Routes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: dataset_routes.html\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp routes.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "from typing import Optional\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "import httpx\n",
    "\n",
    "import domolibrary.client.get_data as gd\n",
    "import domolibrary.client.ResponseGetData as rgd\n",
    "import domolibrary.client.DomoAuth as dmda\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class DatasetNotFoundError(Exception):\n",
    "    def __init__(self, dataset_id, domo_instance):\n",
    "        message = f\"dataset - {dataset_id} not found in {domo_instance}\"\n",
    "\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class QueryRequestError(Exception):\n",
    "    def __init__(self, dataset_id, domo_instance, sql):\n",
    "        message = f\"dataset - {dataset_id} in {domo_instance} received a bad request.  Check your SQL \\n {sql}\"\n",
    "\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "# typically do not use\n",
    "async def query_dataset_public(\n",
    "    dev_auth: dmda.DomoDeveloperAuth,\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: httpx.AsyncClient,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "\n",
    "    \"\"\"query for hitting public apis, requires client_id and secret authentication\"\"\"\n",
    "\n",
    "    url = f\"https://api.domo.com/v1/datasets/query/execute/{dataset_id}?IncludeHeaders=true\"\n",
    "\n",
    "    body = {\"sql\": sql}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=dev_auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "\n",
    "async def query_dataset_private(\n",
    "    auth: dmda.DomoAuth,  # DomoFullAuth or DomoTokenAuth\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    loop_until_end: bool = False,  # retrieve all available rows\n",
    "    limit=100,  # maximum rows to return per request.  refers to PAGINATION\n",
    "    skip=0,\n",
    "    maximum=100,  # equivalent to the LIMIT or TOP clause in SQL, the number of rows to return total\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "):\n",
    "    \"\"\"execute SQL queries against private APIs, requires DomoFullAuth or DomoTokenAuth\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/execute/{dataset_id}\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    def body_fn(skip, limit):\n",
    "        return {\"sql\": f\"{sql} limit {limit} offset {skip}\"}\n",
    "\n",
    "    def arr_fn(res) -> pd.DataFrame:\n",
    "        rows_ls = res.response.get(\"rows\")\n",
    "        columns_ls = res.response.get(\"columns\")\n",
    "        output = []\n",
    "        for row in rows_ls:\n",
    "            new_row = {}\n",
    "            for index, column in enumerate(columns_ls):\n",
    "                new_row[column] = row[index]\n",
    "            output.append(new_row)\n",
    "            # pd.DataFrame(data=res.response.get('rows'), columns=res.response.get('columns'))\n",
    "        return output\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        offset_params=offset_params,\n",
    "        limit=limit,\n",
    "        skip=skip,\n",
    "        maximum=maximum,\n",
    "        session=session,\n",
    "        body_fn=body_fn,\n",
    "        debug_api=debug_api,\n",
    "        debug_loop=debug_loop,\n",
    "        loop_until_end=loop_until_end,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    if res.status == 400 and res.response == \"Bad Request\":\n",
    "        raise QueryRequestError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance, sql=sql\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectID</th>\n",
       "      <th>url</th>\n",
       "      <th>Title</th>\n",
       "      <th>article</th>\n",
       "      <th>views</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>published_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000004790</td>\n",
       "      <td>https://domo-support.domo.com/s/article/360046...</td>\n",
       "      <td>Starting, Stopping, and Restarting the Workben...</td>\n",
       "      <td>Important:  Support for Workbench 4 ended on ...</td>\n",
       "      <td>39</td>\n",
       "      <td>2022-10-24T22:30:00</td>\n",
       "      <td>2022-10-24T22:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000004796</td>\n",
       "      <td>https://domo-support.domo.com/s/article/360047...</td>\n",
       "      <td>Understanding the Workbench 4 User Interface</td>\n",
       "      <td>Important:  Support for Workbench 4 ended on ...</td>\n",
       "      <td>56</td>\n",
       "      <td>2022-10-24T22:30:00</td>\n",
       "      <td>2022-10-24T22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004773</td>\n",
       "      <td>https://domo-support.domo.com/s/article/360046...</td>\n",
       "      <td>Using the External Process File Provider in Wo...</td>\n",
       "      <td>Important:  Support for Workbench 4 ended on ...</td>\n",
       "      <td>20</td>\n",
       "      <td>2022-10-24T22:30:00</td>\n",
       "      <td>2022-10-24T22:41:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004798</td>\n",
       "      <td>https://domo-support.domo.com/s/article/360046...</td>\n",
       "      <td>Workbench 4 FAQs</td>\n",
       "      <td>Important:  Support for Workbench 4 ended on ...</td>\n",
       "      <td>48</td>\n",
       "      <td>2022-10-24T22:30:00</td>\n",
       "      <td>2022-10-24T22:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000004800</td>\n",
       "      <td>https://domo-support.domo.com/s/article/360047...</td>\n",
       "      <td>Workbench 4 Overview</td>\n",
       "      <td>Important:  Support for Workbench 4 ended on ...</td>\n",
       "      <td>40</td>\n",
       "      <td>2022-10-24T22:30:00</td>\n",
       "      <td>2022-10-24T22:41:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    objectID                                                url  \\\n",
       "0  000004790  https://domo-support.domo.com/s/article/360046...   \n",
       "1  000004796  https://domo-support.domo.com/s/article/360047...   \n",
       "2  000004773  https://domo-support.domo.com/s/article/360046...   \n",
       "3  000004798  https://domo-support.domo.com/s/article/360046...   \n",
       "4  000004800  https://domo-support.domo.com/s/article/360047...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Starting, Stopping, and Restarting the Workben...   \n",
       "1       Understanding the Workbench 4 User Interface   \n",
       "2  Using the External Process File Provider in Wo...   \n",
       "3                                   Workbench 4 FAQs   \n",
       "4                               Workbench 4 Overview   \n",
       "\n",
       "                                             article  views  \\\n",
       "0   Important:  Support for Workbench 4 ended on ...     39   \n",
       "1   Important:  Support for Workbench 4 ended on ...     56   \n",
       "2   Important:  Support for Workbench 4 ended on ...     20   \n",
       "3   Important:  Support for Workbench 4 ended on ...     48   \n",
       "4   Important:  Support for Workbench 4 ended on ...     40   \n",
       "\n",
       "            created_dt         published_dt  \n",
       "0  2022-10-24T22:30:00  2022-10-24T22:41:00  \n",
       "1  2022-10-24T22:30:00  2022-10-24T22:40:00  \n",
       "2  2022-10-24T22:30:00  2022-10-24T22:41:00  \n",
       "3  2022-10-24T22:30:00  2022-10-24T22:40:00  \n",
       "4  2022-10-24T22:30:00  2022-10-24T22:41:00  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-dojo\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "sql = f\"SELECT * FROM TABLE\"\n",
    "\n",
    "ds_res = await query_dataset_private(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"],\n",
    "    auth=token_auth,\n",
    "    sql=sql,\n",
    "    skip=42,\n",
    "    maximum=5,\n",
    "    loop_until_end=False,\n",
    ")\n",
    "pd.DataFrame(ds_res.response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_dataset_by_id(\n",
    "    dataset_id: str,  # dataset id from URL\n",
    "    auth: Optional[dmda.DomoAuth] = None,  # requires full authentication\n",
    "    debug_api: bool = False,  # for troubleshooting API request\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    ") -> rgd.ResponseGetData:  # returns metadata about a dataset\n",
    "    \"\"\"retrieve dataset metadata\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth, url=url, method=\"GET\", debug_api=debug_api, session=session\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset - 123 not found in domo-dojo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    token_auth = dmda.DomoTokenAuth(\n",
    "        domo_instance=\"domo-dojo\",\n",
    "        domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    )\n",
    "\n",
    "    await get_dataset_by_id(dataset_id=123, auth=token_auth)\n",
    "\n",
    "except DatasetNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>displayType</th>\n",
       "      <th>dataProviderType</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>owner</th>\n",
       "      <th>status</th>\n",
       "      <th>created</th>\n",
       "      <th>lastTouched</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>...</th>\n",
       "      <th>transportType</th>\n",
       "      <th>adc</th>\n",
       "      <th>adcExternal</th>\n",
       "      <th>cloudId</th>\n",
       "      <th>cloudName</th>\n",
       "      <th>permissions</th>\n",
       "      <th>hidden</th>\n",
       "      <th>tags</th>\n",
       "      <th>scheduleActive</th>\n",
       "      <th>cryoStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04c1574e-c8be-4721-9846-c6ffa491144b</td>\n",
       "      <td>domo-jupyterdata</td>\n",
       "      <td>domo-jupyterdata</td>\n",
       "      <td>Jupyter</td>\n",
       "      <td>domo_kbs</td>\n",
       "      <td>{'id': '1893952720', 'name': 'Jae Wilson', 'ty...</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>1668379680000</td>\n",
       "      <td>1668385822000</td>\n",
       "      <td>1668385822045</td>\n",
       "      <td>...</td>\n",
       "      <td>API</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>domo</td>\n",
       "      <td>Domo</td>\n",
       "      <td>READ_WRITE_DELETE_SHARE_ADMIN</td>\n",
       "      <td>False</td>\n",
       "      <td>[\"developer_documentation\",\"hackercore\"]</td>\n",
       "      <td>True</td>\n",
       "      <td>ADRENALINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id       displayType  dataProviderType  \\\n",
       "0  04c1574e-c8be-4721-9846-c6ffa491144b  domo-jupyterdata  domo-jupyterdata   \n",
       "\n",
       "      type      name                                              owner  \\\n",
       "0  Jupyter  domo_kbs  {'id': '1893952720', 'name': 'Jae Wilson', 'ty...   \n",
       "\n",
       "    status        created    lastTouched    lastUpdated  ...  transportType  \\\n",
       "0  SUCCESS  1668379680000  1668385822000  1668385822045  ...            API   \n",
       "\n",
       "     adc adcExternal cloudId cloudName                    permissions  hidden  \\\n",
       "0  False       False    domo      Domo  READ_WRITE_DELETE_SHARE_ADMIN   False   \n",
       "\n",
       "                                       tags scheduleActive  cryoStatus  \n",
       "0  [\"developer_documentation\",\"hackercore\"]           True  ADRENALINE  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-dojo\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "ds_res = await get_dataset_by_id(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth\n",
    ")\n",
    "pd.DataFrame([ds_res.response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_schema(\n",
    "    auth: dmda.DomoAuth, dataset_id: str, debug_api: bool = False\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"retrieve the schema for a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/schema/indexed?includeHidden=false\"\n",
    "\n",
    "    return await gd.get_data(auth=auth, url=url, method=\"GET\", debug_api=debug_api)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of get_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tables</th>\n",
       "      <th>dataSourceId</th>\n",
       "      <th>url</th>\n",
       "      <th>queryEndpoint</th>\n",
       "      <th>progressEndpoint</th>\n",
       "      <th>indexEndpoint</th>\n",
       "      <th>deleteEndpoint</th>\n",
       "      <th>versionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>domo_kbs</td>\n",
       "      <td>{'columns': [{'name': 'objectID', 'id': 'objec...</td>\n",
       "      <td>04c1574e-c8be-4721-9846-c6ffa491144b</td>\n",
       "      <td>/schemas/853832B128D75BCE</td>\n",
       "      <td>/query/mmmm-0012-0200/04c1574e-c8be-4721-9846-...</td>\n",
       "      <td>/index/mmmm-0012-0200/04c1574e-c8be-4721-9846-...</td>\n",
       "      <td>/index/mmmm-0012-0200/04c1574e-c8be-4721-9846-...</td>\n",
       "      <td>/delete/mmmm-0012-0200/04c1574e-c8be-4721-9846...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                             tables  \\\n",
       "0  domo_kbs  {'columns': [{'name': 'objectID', 'id': 'objec...   \n",
       "\n",
       "                           dataSourceId                        url  \\\n",
       "0  04c1574e-c8be-4721-9846-c6ffa491144b  /schemas/853832B128D75BCE   \n",
       "\n",
       "                                       queryEndpoint  \\\n",
       "0  /query/mmmm-0012-0200/04c1574e-c8be-4721-9846-...   \n",
       "\n",
       "                                    progressEndpoint  \\\n",
       "0  /index/mmmm-0012-0200/04c1574e-c8be-4721-9846-...   \n",
       "\n",
       "                                       indexEndpoint  \\\n",
       "0  /index/mmmm-0012-0200/04c1574e-c8be-4721-9846-...   \n",
       "\n",
       "                                      deleteEndpoint versionId  \n",
       "0  /delete/mmmm-0012-0200/04c1574e-c8be-4721-9846...         3  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-dojo\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "ds_res = await get_schema(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth)\n",
    "pd.DataFrame(ds_res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>visible</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>objectID</td>\n",
       "      <td>objectID</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>url</td>\n",
       "      <td>url</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title</td>\n",
       "      <td>Title</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article</td>\n",
       "      <td>article</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>views</td>\n",
       "      <td>views</td>\n",
       "      <td>LONG</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>created_dt</td>\n",
       "      <td>created_dt</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>published_dt</td>\n",
       "      <td>published_dt</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name            id      type  visible  order\n",
       "0      objectID      objectID    STRING     True      0\n",
       "1           url           url    STRING     True      0\n",
       "2         Title         Title    STRING     True      0\n",
       "3       article       article    STRING     True      0\n",
       "4         views         views      LONG     True      0\n",
       "5    created_dt    created_dt  DATETIME     True      0\n",
       "6  published_dt  published_dt  DATETIME     True      0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve schema from response\n",
    "pd.DataFrame(ds_res.response.get(\"tables\")[0].get(\"columns\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def set_dataset_tags(\n",
    "    auth: dmda.DomoFullAuth,\n",
    "    tag_ls: [str],  # complete list of tags for dataset\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    return_raw: bool = False,\n",
    "):\n",
    "\n",
    "    \"\"\"REPLACE tags on this dataset with a new list\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/ui/v3/datasources/{dataset_id}/tags\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        debug_api=debug_api,\n",
    "        body=tag_ls,\n",
    "        session=session,\n",
    "        return_raw=return_raw,\n",
    "    )\n",
    "\n",
    "    if return_raw:\n",
    "        return res\n",
    "\n",
    "    if res.status == 200:\n",
    "        res.set_response(\n",
    "            response=f'Dataset {dataset_id} tags updated to [{ \", \".join(tag_ls) }]'\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseGetData(status=200, response='Dataset 04c1574e-c8be-4721-9846-c6ffa491144b tags updated to [hackercore, developer_documentation]', is_success=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    domo_instance=\"domo-dojo\",\n",
    ")\n",
    "\n",
    "tag_ls = [\"hackercore\", \"developer_documentation\"]\n",
    "\n",
    "await set_dataset_tags(\n",
    "    auth=token_auth,\n",
    "    tag_ls=tag_ls,\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"],\n",
    "    debug_api=False,\n",
    "    return_raw=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "#### overview\n",
    "\n",
    "In the URL, parts refers to the multi-part API and is unrelated to the partitions concept. The multi-part API was designed to allow sending multiple streams of Data into a data_version simultaneously.\n",
    "\n",
    "In stage 1, the values passed in the Body will be superseded by values in the COMMIT (stage 3), so best practices is to not populate values here.\n",
    "\n",
    "The response includes an uploadId, which must be stored and passed to the URL of the subsequent upload request (stages 2 and 3).\n",
    "\n",
    "#### url params\n",
    "\n",
    "The dataTag parameter allows users to UPDATE or REPLACE a datatag (partition)\n",
    "\n",
    "NOTE: restateDataTag is largely deprecated // exists for backward compatibility\n",
    "\n",
    "#### body params\n",
    "\n",
    "The appendId parameter accepts \"latest\" or \"None\"\n",
    "\n",
    "latest will APPEND the data version to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class UploadDataError(Exception):\n",
    "    \"\"\"raise if unable to upload data to Domo\"\"\"\n",
    "\n",
    "    def __init__(self, stage_num: int, dataset_id: str, domo_instance: str):\n",
    "        message = f\"error uploading data to {dataset_id} during Stage { stage_num} in {domo_instance}\"\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_1(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    \"\"\"preps dataset for upload by creating an upload_id (upload session key) pass to stage 2 as a parameter\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads\"\n",
    "\n",
    "    # base body assumes no paritioning\n",
    "    body = {\"action\": None, \"appendId\": None}\n",
    "\n",
    "    params = None\n",
    "\n",
    "    if partition_tag:\n",
    "        # params = {'dataTag': restate_data_tag or data_tag} # deprecated\n",
    "        params = {\"dataTag\": partition_tag}\n",
    "        body.update({\"appendId\": \"latest\"})\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=1, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_2_file(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    data_file: Optional[io.TextIOWrapper] = None,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    part_id: str = 2,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = data_file\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def upload_dataset_stage_2_df(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    upload_df: pd.DataFrame,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    part_id: str = 2,  # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = upload_df.to_csv(header=False, index=False)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(body)\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_3(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    update_method: str = \"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    is_index: bool = False,  # index after uploading\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    \"\"\"commit will close the upload session, upload_id.  this request defines how the data will be loaded into Adrenaline, update_method\n",
    "    has optional flag for indexing dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/commit\"\n",
    "\n",
    "    body = {\"index\": is_index, \"action\": update_method}\n",
    "\n",
    "    if partition_tag:\n",
    "\n",
    "        body.update(\n",
    "            {\n",
    "                \"action\": \"APPEND\",\n",
    "                #  'dataTag': restate_data_tag or data_tag,\n",
    "                #  'appendId': 'latest' if (restate_data_tag or data_tag) else None,\n",
    "                \"dataTag\": partition_tag,\n",
    "                \"appendId\": \"latest\" if partition_tag else None,\n",
    "                \"index\": is_index,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"PUT\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=3, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-dojo\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "ds_id = \"cbae0e0c-a92d-4a4c-8d0c-c9ccd38fe928\"\n",
    "\n",
    "# await get_schema(dataset_id= ds_id, auth=token_auth)\n",
    "\n",
    "df = pd.DataFrame([{\"col_a\": \"a\", \"col_b\": \"b\", \"col_c\": \"c\"}])\n",
    "\n",
    "\n",
    "s1_res = await upload_dataset_stage_1(\n",
    "    auth=token_auth, dataset_id=ds_id, partition_tag=None, debug_api=False\n",
    ")\n",
    "\n",
    "upload_id = s1_res.response.get(\"uploadId\")\n",
    "upload_id\n",
    "\n",
    "s2_res = await upload_dataset_stage_2_df(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    upload_df=df,\n",
    "    part_id=2,\n",
    "    debug_api=False,\n",
    ")\n",
    "\n",
    "\n",
    "s3_res = await upload_dataset_stage_3(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    update_method=\"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    is_index=True,  # index after uploading\n",
    ")\n",
    "\n",
    "s3_res.is_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def index_dataset(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"manually index a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes\"\n",
    "\n",
    "    body = {\"dataIds\": []}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        url=url,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def index_status(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    index_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"get the completion status of an index\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes/{index_id}/statuses\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"GET\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_list_partitions_body(limit=100, offset=0):\n",
    "    return {\n",
    "        \"paginationFields\": [\n",
    "            {\n",
    "                \"fieldName\": \"datecompleted\",\n",
    "                \"sortOrder\": \"DESC\",\n",
    "                \"filterValues\": {\"MIN\": None, \"MAX\": None},\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset,\n",
    "    }\n",
    "\n",
    "\n",
    "async def list_partitions(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    body: dict = None,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "):\n",
    "\n",
    "    body = body or generate_list_partitions_body()\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/list\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    def arr_fn(res) -> list[dict]:\n",
    "        return res.response\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        body=body,\n",
    "        offset_params_in_body=True,\n",
    "        offset_params=offset_params,\n",
    "        loop_until_end=True,\n",
    "        session=session,\n",
    "        debug_loop=debug_loop,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataId</th>\n",
       "      <th>partitionId</th>\n",
       "      <th>dateCompleted</th>\n",
       "      <th>rowCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>372</td>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>2023-01-24T14:27:21.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2023-01-24T14:27:21.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>2013-07-20</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355</td>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>2013-07-18</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataId partitionId                  dateCompleted  rowCount\n",
       "0     372  2013-07-02  2023-01-24T14:27:21.000+00:00         1\n",
       "1     373  2013-07-01  2023-01-24T14:27:21.000+00:00         1\n",
       "2     354  2013-07-20  2023-01-24T14:27:20.000+00:00         1\n",
       "3     355  2013-07-19  2023-01-24T14:27:20.000+00:00         1\n",
       "4     356  2013-07-18  2023-01-24T14:27:20.000+00:00         1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-dojo\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "dataset_id = \"d2b21660-4ba8-400c-badf-aeef5a9abae1\"\n",
    "\n",
    "res = await list_partitions(auth=token_auth, dataset_id=dataset_id)\n",
    "\n",
    "ds_partition_ls = res.response\n",
    "\n",
    "pd.DataFrame(ds_partition_ls[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_create_dataset_body(\n",
    "    dataset_name: str, dataset_type: str = \"API\", schema: dict = None\n",
    "):\n",
    "    schema = schema or {\n",
    "        \"columns\": [\n",
    "            {\"type\": \"STRING\", \"name\": \"Friend\"},\n",
    "            {\"type\": \"STRING\", \"name\": \"Attending\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"userDefinedType\": dataset_type,\n",
    "        \"dataSourceName\": dataset_name,\n",
    "        \"schema\": schema,\n",
    "    }\n",
    "\n",
    "\n",
    "async def create(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_name: str,\n",
    "    dataset_type: str = \"api\",\n",
    "    session: httpx.AsyncClient = None,\n",
    "    schema: dict = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "\n",
    "    body = generate_create_dataset_body(\n",
    "        dataset_name=dataset_name, dataset_type=dataset_type, schema=schema\n",
    "    )\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v2/datasources\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-dojo\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "# await create(dataset_name = 'hello world', dataset_type = 'api', auth = token_auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delete partition has 3 stages\n",
    "# # Stage 1. This marks the data version associated with the partition tag as deleted.  It does not delete the partition tag or remove the association between the partition tag and data version.  There should be no need to upload an empty file – step #3 will remove the data from Adrenaline.\n",
    "# #| export\n",
    "# async def delete_partition_stage_1(full_auth: DomoFullAuth,\n",
    "#                                    dataset_id: str,\n",
    "#                                    dataset_partition_id: str,\n",
    "#                                    session: httpx.AsyncClient = None,\n",
    "#                                    debug: bool = False):\n",
    "\n",
    "#     #url = f'https://{full_auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/{dataset_partition_id}'\n",
    "#     # update on 9/9/2022 based on the conversation with Greg Swensen\n",
    "#     url = f'https://{full_auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/tag/{dataset_partition_id}/data'\n",
    "\n",
    "#     return await get_data(\n",
    "#         auth=full_auth,\n",
    "#         method=\"DELETE\",\n",
    "#         url=url,\n",
    "#         session=session,\n",
    "#         debug=debug\n",
    "#     )\n",
    "# # Stage 2. This will remove the partition association so that it doesn’t show up in the list call.  Technically, this is not required as a partition against a deleted data version will not count against the 400 partition limit, but as the current partitions api doesn’t make that clear, cleaning these up will make it much easier for you to manage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# async def delete_partition_stage_2(full_auth: DomoFullAuth,\n",
    "#                                    dataset_id: str,\n",
    "#                                    dataset_partition_id: str,\n",
    "#                                    session: httpx.AsyncClient = None,\n",
    "#                                    debug: bool = False):\n",
    "\n",
    "#     url = f'https://{full_auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/{dataset_partition_id}'\n",
    "\n",
    "#     return await get_data(\n",
    "#         auth=full_auth,\n",
    "#         method=\"DELETE\",\n",
    "#         url=url,\n",
    "#         session=session,\n",
    "#         debug=debug\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}?deleteMethod=hard\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"DELETE\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

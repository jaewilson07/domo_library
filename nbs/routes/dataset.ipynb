{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Routes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: dataset_routes.html\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp routes.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "from typing import Optional\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "import httpx\n",
    "\n",
    "import domolibrary.client.get_data as gd\n",
    "import domolibrary.client.ResponseGetData as rgd\n",
    "import domolibrary.client.DomoAuth as dmda\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class DatasetNotFoundError(Exception):\n",
    "    def __init__(self, dataset_id, domo_instance):\n",
    "        message = f\"dataset - {dataset_id} not found in {domo_instance}\"\n",
    "\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class QueryRequestError(Exception):\n",
    "    def __init__(self, dataset_id, domo_instance, sql):\n",
    "        message = f\"dataset - {dataset_id} in {domo_instance} received a bad request.  Check your SQL \\n {sql}\"\n",
    "\n",
    "        super().__init__(message)\n",
    "\n",
    "\n",
    "# typically do not use\n",
    "async def query_dataset_public(\n",
    "    dev_auth: dmda.DomoDeveloperAuth,\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: httpx.AsyncClient,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "\n",
    "    \"\"\"query for hitting public apis, requires client_id and secret authentication\"\"\"\n",
    "\n",
    "    url = f\"https://api.domo.com/v1/datasets/query/execute/{dataset_id}?IncludeHeaders=true\"\n",
    "\n",
    "    body = {\"sql\": sql}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=dev_auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "\n",
    "async def query_dataset_private(\n",
    "    auth: dmda.DomoAuth,  # DomoFullAuth or DomoTokenAuth\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    loop_until_end: bool = False,  # retrieve all available rows\n",
    "    limit=100,  # maximum rows to return per request.  refers to PAGINATION\n",
    "    skip=0,\n",
    "    maximum=100,  # equivalent to the LIMIT or TOP clause in SQL, the number of rows to return total\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "    timeout :int = 10\n",
    "):\n",
    "    \"\"\"execute SQL queries against private APIs, requires DomoFullAuth or DomoTokenAuth\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/execute/{dataset_id}\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    def body_fn(skip, limit):\n",
    "        return {\"sql\": f\"{sql} limit {limit} offset {skip}\"}\n",
    "\n",
    "    def arr_fn(res) -> pd.DataFrame:\n",
    "        rows_ls = res.response.get(\"rows\")\n",
    "        columns_ls = res.response.get(\"columns\")\n",
    "        output = []\n",
    "        for row in rows_ls:\n",
    "            new_row = {}\n",
    "            for index, column in enumerate(columns_ls):\n",
    "                new_row[column] = row[index]\n",
    "            output.append(new_row)\n",
    "            # pd.DataFrame(data=res.response.get('rows'), columns=res.response.get('columns'))\n",
    "        return output\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        offset_params=offset_params,\n",
    "        limit=limit,\n",
    "        skip=skip,\n",
    "        maximum=maximum,\n",
    "        session=session,\n",
    "        body_fn=body_fn,\n",
    "        debug_api=debug_api,\n",
    "        debug_loop=debug_loop,\n",
    "        loop_until_end=loop_until_end,\n",
    "        timeout = timeout\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    if res.status == 400 and res.response == \"Bad Request\":\n",
    "        raise QueryRequestError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance, sql=sql\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Row Count</th>\n",
       "      <th>Column Count</th>\n",
       "      <th>Owner ID</th>\n",
       "      <th>Owner Name</th>\n",
       "      <th>Dataset Created Date/Time</th>\n",
       "      <th>DataSet Last Touched Date/Time</th>\n",
       "      <th>DataSet Last Updated Date/Time</th>\n",
       "      <th>Report Last Run</th>\n",
       "      <th>Type</th>\n",
       "      <th>Display ProcessingType</th>\n",
       "      <th>Data Provider ProcessingType</th>\n",
       "      <th>Card Count</th>\n",
       "      <th>PDP Enabled</th>\n",
       "      <th>_BATCH_ID_</th>\n",
       "      <th>_BATCH_LAST_RUN_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>598d6954-9526-48d3-8658-9f6fc0aa05c0</td>\n",
       "      <td>android_reviews_sent</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1893952720</td>\n",
       "      <td>Jae Wilson1</td>\n",
       "      <td>2022-11-06T23:46:17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2023-04-27T20:01:17</td>\n",
       "      <td>Jupyter</td>\n",
       "      <td>domo-jupyterdata</td>\n",
       "      <td>domo-jupyterdata</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2023-04-27T20:01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7832f21c-ad8f-4b44-8965-7ed4da2d1162</td>\n",
       "      <td>Anonymized data for DOJO.xlsx</td>\n",
       "      <td>https://dojo.domo.com/discussion/53804/is-this...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>55874022</td>\n",
       "      <td>Grant Smith</td>\n",
       "      <td>2021-11-10T13:06:08</td>\n",
       "      <td>2021-11-10T13:06:23</td>\n",
       "      <td>2021-11-10T13:06:22</td>\n",
       "      <td>2023-04-27T20:01:17</td>\n",
       "      <td>large-file-upload</td>\n",
       "      <td>large-file-upload</td>\n",
       "      <td>large-file-upload</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2023-04-27T20:01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7b66440e-4f49-46d1-bda1-72325684c68e</td>\n",
       "      <td>ap1999 rolling StdDev</td>\n",
       "      <td></td>\n",
       "      <td>120.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>966365811</td>\n",
       "      <td>Scott Thompson</td>\n",
       "      <td>2023-04-21T16:43:10</td>\n",
       "      <td>2023-04-21T17:22:12</td>\n",
       "      <td>2023-04-21T17:22:12</td>\n",
       "      <td>2023-04-27T20:01:17</td>\n",
       "      <td>DataFlow</td>\n",
       "      <td>DataFlow</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2023-04-27T20:01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56d5e7a1-554e-4169-9a9d-b86f3c57cdd3</td>\n",
       "      <td>Append Dataflow - CLI (FAST)</td>\n",
       "      <td></td>\n",
       "      <td>33884556.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68216396</td>\n",
       "      <td>Elliott Leonard</td>\n",
       "      <td>2023-01-01T06:18:45</td>\n",
       "      <td>2023-01-01T06:29:27</td>\n",
       "      <td>2023-01-01T06:29:26</td>\n",
       "      <td>2023-04-27T20:01:17</td>\n",
       "      <td>DataFlow</td>\n",
       "      <td>DataFlow</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2023-04-27T20:01:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8d372276-d40b-4e7e-b929-0827a77bee67</td>\n",
       "      <td>Appt Reminder Test Data</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68216396</td>\n",
       "      <td>Elliott Leonard</td>\n",
       "      <td>2022-05-16T23:15:36</td>\n",
       "      <td>2022-05-16T23:15:43</td>\n",
       "      <td>2022-05-16T23:15:43</td>\n",
       "      <td>2023-04-27T20:01:17</td>\n",
       "      <td>webform</td>\n",
       "      <td>webform</td>\n",
       "      <td>webform</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>177.0</td>\n",
       "      <td>2023-04-27T20:01:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dataset ID                           Name   \n",
       "0  598d6954-9526-48d3-8658-9f6fc0aa05c0           android_reviews_sent  \\\n",
       "1  7832f21c-ad8f-4b44-8965-7ed4da2d1162  Anonymized data for DOJO.xlsx   \n",
       "2  7b66440e-4f49-46d1-bda1-72325684c68e          ap1999 rolling StdDev   \n",
       "3  56d5e7a1-554e-4169-9a9d-b86f3c57cdd3   Append Dataflow - CLI (FAST)   \n",
       "4  8d372276-d40b-4e7e-b929-0827a77bee67        Appt Reminder Test Data   \n",
       "\n",
       "                                         Description   Row Count   \n",
       "0                                                            0.0  \\\n",
       "1  https://dojo.domo.com/discussion/53804/is-this...        30.0   \n",
       "2                                                          120.0   \n",
       "3                                                     33884556.0   \n",
       "4                                                            5.0   \n",
       "\n",
       "   Column Count    Owner ID       Owner Name Dataset Created Date/Time   \n",
       "0           0.0  1893952720      Jae Wilson1       2022-11-06T23:46:17  \\\n",
       "1           3.0    55874022      Grant Smith       2021-11-10T13:06:08   \n",
       "2           3.0   966365811   Scott Thompson       2023-04-21T16:43:10   \n",
       "3           6.0    68216396  Elliott Leonard       2023-01-01T06:18:45   \n",
       "4           2.0    68216396  Elliott Leonard       2022-05-16T23:15:36   \n",
       "\n",
       "  DataSet Last Touched Date/Time DataSet Last Updated Date/Time   \n",
       "0                                                                \\\n",
       "1            2021-11-10T13:06:23            2021-11-10T13:06:22   \n",
       "2            2023-04-21T17:22:12            2023-04-21T17:22:12   \n",
       "3            2023-01-01T06:29:27            2023-01-01T06:29:26   \n",
       "4            2022-05-16T23:15:43            2022-05-16T23:15:43   \n",
       "\n",
       "       Report Last Run               Type Display ProcessingType   \n",
       "0  2023-04-27T20:01:17            Jupyter       domo-jupyterdata  \\\n",
       "1  2023-04-27T20:01:17  large-file-upload      large-file-upload   \n",
       "2  2023-04-27T20:01:17           DataFlow               DataFlow   \n",
       "3  2023-04-27T20:01:17           DataFlow               DataFlow   \n",
       "4  2023-04-27T20:01:17            webform                webform   \n",
       "\n",
       "  Data Provider ProcessingType Card Count PDP Enabled  _BATCH_ID_   \n",
       "0             domo-jupyterdata          0       false       177.0  \\\n",
       "1            large-file-upload          0       false       177.0   \n",
       "2                                       0       false       177.0   \n",
       "3                                       0       false       177.0   \n",
       "4                      webform          0       false       177.0   \n",
       "\n",
       "      _BATCH_LAST_RUN_  \n",
       "0  2023-04-27T20:01:13  \n",
       "1  2023-04-27T20:01:13  \n",
       "2  2023-04-27T20:01:13  \n",
       "3  2023-04-27T20:01:13  \n",
       "4  2023-04-27T20:01:13  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "sql = f\"SELECT * FROM TABLE\"\n",
    "\n",
    "ds_res = await query_dataset_private(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"],\n",
    "    auth=token_auth,\n",
    "    sql=sql,\n",
    "    skip=42,\n",
    "    maximum=5,\n",
    "    loop_until_end=False,\n",
    ")\n",
    "pd.DataFrame(ds_res.response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_dataset_by_id(\n",
    "    dataset_id: str,  # dataset id from URL\n",
    "    auth: Optional[dmda.DomoAuth] = None,  # requires full authentication\n",
    "    debug_api: bool = False,  # for troubleshooting API request\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    ") -> rgd.ResponseGetData:  # returns metadata about a dataset\n",
    "    \"\"\"retrieve dataset metadata\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth, url=url, method=\"GET\", debug_api=debug_api, session=session\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset - 123 not found in domo-community\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    token_auth = dmda.DomoTokenAuth(\n",
    "        domo_instance=\"domo-community\",\n",
    "        domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    )\n",
    "\n",
    "    await get_dataset_by_id(dataset_id=123, auth=token_auth)\n",
    "\n",
    "except DatasetNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>displayType</th>\n",
       "      <th>dataProviderType</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>owner</th>\n",
       "      <th>status</th>\n",
       "      <th>created</th>\n",
       "      <th>lastTouched</th>\n",
       "      <th>...</th>\n",
       "      <th>adc</th>\n",
       "      <th>adcExternal</th>\n",
       "      <th>adcSource</th>\n",
       "      <th>cloudId</th>\n",
       "      <th>cloudName</th>\n",
       "      <th>permissions</th>\n",
       "      <th>hidden</th>\n",
       "      <th>tags</th>\n",
       "      <th>scheduleActive</th>\n",
       "      <th>cryoStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42917df1-fa58-483f-a290-5fe95ccda4ed</td>\n",
       "      <td>domo-governance-d14c2fef-49a8-4898-8ddd-f64998...</td>\n",
       "      <td>domo-governance-d14c2fef-49a8-4898-8ddd-f64998...</td>\n",
       "      <td>domo-governance-d14c2fef-49a8-4898-8ddd-f64998...</td>\n",
       "      <td>Governance_datasets</td>\n",
       "      <td></td>\n",
       "      <td>{'id': '612085674', 'name': 'Oleksii Zakrevsky...</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>1667420782000</td>\n",
       "      <td>1682625739000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>domo</td>\n",
       "      <td>Domo</td>\n",
       "      <td>NONE</td>\n",
       "      <td>False</td>\n",
       "      <td>[\"developer_documentation\",\"Apr-27-2023 21:46\"...</td>\n",
       "      <td>True</td>\n",
       "      <td>ADRENALINE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id   \n",
       "0  42917df1-fa58-483f-a290-5fe95ccda4ed  \\\n",
       "\n",
       "                                         displayType   \n",
       "0  domo-governance-d14c2fef-49a8-4898-8ddd-f64998...  \\\n",
       "\n",
       "                                    dataProviderType   \n",
       "0  domo-governance-d14c2fef-49a8-4898-8ddd-f64998...  \\\n",
       "\n",
       "                                                type                 name   \n",
       "0  domo-governance-d14c2fef-49a8-4898-8ddd-f64998...  Governance_datasets  \\\n",
       "\n",
       "  description                                              owner   status   \n",
       "0              {'id': '612085674', 'name': 'Oleksii Zakrevsky...  SUCCESS  \\\n",
       "\n",
       "         created    lastTouched  ...   adc  adcExternal  adcSource  cloudId   \n",
       "0  1667420782000  1682625739000  ...  True        False     DIRECT     domo  \\\n",
       "\n",
       "  cloudName permissions hidden   \n",
       "0      Domo        NONE  False  \\\n",
       "\n",
       "                                                tags  scheduleActive   \n",
       "0  [\"developer_documentation\",\"Apr-27-2023 21:46\"...            True  \\\n",
       "\n",
       "   cryoStatus  \n",
       "0  ADRENALINE  \n",
       "\n",
       "[1 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "ds_res = await get_dataset_by_id(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth\n",
    ")\n",
    "pd.DataFrame([ds_res.response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_schema(\n",
    "    auth: dmda.DomoAuth, dataset_id: str, debug_api: bool = False\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"retrieve the schema for a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/schema/indexed?includeHidden=false\"\n",
    "\n",
    "    return await gd.get_data(auth=auth, url=url, method=\"GET\", debug_api=debug_api)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of get_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tables</th>\n",
       "      <th>dataSourceId</th>\n",
       "      <th>url</th>\n",
       "      <th>queryEndpoint</th>\n",
       "      <th>progressEndpoint</th>\n",
       "      <th>indexEndpoint</th>\n",
       "      <th>deleteEndpoint</th>\n",
       "      <th>versionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main</td>\n",
       "      <td>{'columns': [{'name': 'Dataset ID', 'id': 'Dat...</td>\n",
       "      <td>42917df1-fa58-483f-a290-5fe95ccda4ed</td>\n",
       "      <td>/schemas/D07048480F19795F</td>\n",
       "      <td>/query/mmmm-0012-0200/42917df1-fa58-483f-a290-...</td>\n",
       "      <td>/index/mmmm-0012-0200/42917df1-fa58-483f-a290-...</td>\n",
       "      <td>/index/mmmm-0012-0200/42917df1-fa58-483f-a290-...</td>\n",
       "      <td>/delete/mmmm-0012-0200/42917df1-fa58-483f-a290...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                             tables   \n",
       "0  main  {'columns': [{'name': 'Dataset ID', 'id': 'Dat...  \\\n",
       "\n",
       "                           dataSourceId                        url   \n",
       "0  42917df1-fa58-483f-a290-5fe95ccda4ed  /schemas/D07048480F19795F  \\\n",
       "\n",
       "                                       queryEndpoint   \n",
       "0  /query/mmmm-0012-0200/42917df1-fa58-483f-a290-...  \\\n",
       "\n",
       "                                    progressEndpoint   \n",
       "0  /index/mmmm-0012-0200/42917df1-fa58-483f-a290-...  \\\n",
       "\n",
       "                                       indexEndpoint   \n",
       "0  /index/mmmm-0012-0200/42917df1-fa58-483f-a290-...  \\\n",
       "\n",
       "                                      deleteEndpoint versionId  \n",
       "0  /delete/mmmm-0012-0200/42917df1-fa58-483f-a290...         1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "ds_res = await get_schema(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth)\n",
    "pd.DataFrame(ds_res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>visible</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset ID</td>\n",
       "      <td>Dataset ID</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name</td>\n",
       "      <td>Name</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Description</td>\n",
       "      <td>Description</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Row Count</td>\n",
       "      <td>Row Count</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Column Count</td>\n",
       "      <td>Column Count</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Owner ID</td>\n",
       "      <td>Owner ID</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Owner Name</td>\n",
       "      <td>Owner Name</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dataset Created Date/Time</td>\n",
       "      <td>Dataset Created Date/Time</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DataSet Last Touched Date/Time</td>\n",
       "      <td>DataSet Last Touched Date/Time</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DataSet Last Updated Date/Time</td>\n",
       "      <td>DataSet Last Updated Date/Time</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Report Last Run</td>\n",
       "      <td>Report Last Run</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Type</td>\n",
       "      <td>Type</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Display ProcessingType</td>\n",
       "      <td>Display ProcessingType</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Provider ProcessingType</td>\n",
       "      <td>Data Provider ProcessingType</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Card Count</td>\n",
       "      <td>Card Count</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PDP Enabled</td>\n",
       "      <td>PDP Enabled</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>_BATCH_ID_</td>\n",
       "      <td>_BATCH_ID_</td>\n",
       "      <td>DOUBLE</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>_BATCH_LAST_RUN_</td>\n",
       "      <td>_BATCH_LAST_RUN_</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name                              id      type   \n",
       "0                       Dataset ID                      Dataset ID    STRING  \\\n",
       "1                             Name                            Name    STRING   \n",
       "2                      Description                     Description    STRING   \n",
       "3                        Row Count                       Row Count    DOUBLE   \n",
       "4                     Column Count                    Column Count    DOUBLE   \n",
       "5                         Owner ID                        Owner ID    STRING   \n",
       "6                       Owner Name                      Owner Name    STRING   \n",
       "7        Dataset Created Date/Time       Dataset Created Date/Time  DATETIME   \n",
       "8   DataSet Last Touched Date/Time  DataSet Last Touched Date/Time  DATETIME   \n",
       "9   DataSet Last Updated Date/Time  DataSet Last Updated Date/Time  DATETIME   \n",
       "10                 Report Last Run                 Report Last Run  DATETIME   \n",
       "11                            Type                            Type    STRING   \n",
       "12          Display ProcessingType          Display ProcessingType    STRING   \n",
       "13    Data Provider ProcessingType    Data Provider ProcessingType    STRING   \n",
       "14                      Card Count                      Card Count    STRING   \n",
       "15                     PDP Enabled                     PDP Enabled    STRING   \n",
       "16                      _BATCH_ID_                      _BATCH_ID_    DOUBLE   \n",
       "17                _BATCH_LAST_RUN_                _BATCH_LAST_RUN_  DATETIME   \n",
       "\n",
       "    visible  order  \n",
       "0      True      0  \n",
       "1      True      0  \n",
       "2      True      0  \n",
       "3      True      0  \n",
       "4      True      0  \n",
       "5      True      0  \n",
       "6      True      0  \n",
       "7      True      0  \n",
       "8      True      0  \n",
       "9      True      0  \n",
       "10     True      0  \n",
       "11     True      0  \n",
       "12     True      0  \n",
       "13     True      0  \n",
       "14     True      0  \n",
       "15     True      0  \n",
       "16     True      0  \n",
       "17     True      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve schema from response\n",
    "pd.DataFrame(ds_res.response.get(\"tables\")[0].get(\"columns\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def set_dataset_tags(\n",
    "    auth: dmda.DomoFullAuth,\n",
    "    tag_ls: [str],  # complete list of tags for dataset\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    return_raw: bool = False,\n",
    "):\n",
    "\n",
    "    \"\"\"REPLACE tags on this dataset with a new list\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/ui/v3/datasources/{dataset_id}/tags\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        debug_api=debug_api,\n",
    "        body=tag_ls,\n",
    "        session=session,\n",
    "        return_raw=return_raw,\n",
    "    )\n",
    "\n",
    "    if return_raw:\n",
    "        return res\n",
    "\n",
    "    if res.status == 200:\n",
    "        res.set_response(\n",
    "            response=f'Dataset {dataset_id} tags updated to [{ \", \".join(tag_ls) }]'\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseGetData(status=200, response='Dataset 42917df1-fa58-483f-a290-5fe95ccda4ed tags updated to [hackercore, developer_documentation]', is_success=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    domo_instance=\"domo-community\",\n",
    ")\n",
    "\n",
    "tag_ls = [\"hackercore\", \"developer_documentation\"]\n",
    "\n",
    "await set_dataset_tags(\n",
    "    auth=token_auth,\n",
    "    tag_ls=tag_ls,\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"],\n",
    "    debug_api=False,\n",
    "    return_raw=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "#### overview\n",
    "\n",
    "In the URL, parts refers to the multi-part API and is unrelated to the partitions concept. The multi-part API was designed to allow sending multiple streams of Data into a data_version simultaneously.\n",
    "\n",
    "In stage 1, the values passed in the Body will be superseded by values in the COMMIT (stage 3), so best practices is to not populate values here.\n",
    "\n",
    "The response includes an uploadId, which must be stored and passed to the URL of the subsequent upload request (stages 2 and 3).\n",
    "\n",
    "#### url params\n",
    "\n",
    "The dataTag parameter allows users to UPDATE or REPLACE a datatag (partition)\n",
    "\n",
    "NOTE: restateDataTag is largely deprecated // exists for backward compatibility\n",
    "\n",
    "#### body params\n",
    "\n",
    "The appendId parameter accepts \"latest\" or \"None\"\n",
    "\n",
    "latest will APPEND the data version to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class UploadDataError(Exception):\n",
    "    \"\"\"raise if unable to upload data to Domo\"\"\"\n",
    "\n",
    "    def __init__(self, stage_num: int, dataset_id: str, domo_instance: str):\n",
    "        message = f\"error uploading data to {dataset_id} during Stage { stage_num} in {domo_instance}\"\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_1(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    \"\"\"preps dataset for upload by creating an upload_id (upload session key) pass to stage 2 as a parameter\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads\"\n",
    "\n",
    "    # base body assumes no paritioning\n",
    "    body = {\"action\": None, \"appendId\": None}\n",
    "\n",
    "    params = None\n",
    "\n",
    "    if partition_tag:\n",
    "        # params = {'dataTag': restate_data_tag or data_tag} # deprecated\n",
    "        params = {\"dataTag\": partition_tag}\n",
    "        body.update({\"appendId\": \"latest\"})\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=1, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_2_file(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    data_file: Optional[io.TextIOWrapper] = None,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    part_id: str = 2,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = data_file\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def upload_dataset_stage_2_df(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    upload_df: pd.DataFrame,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    part_id: str = 2,  # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = upload_df.to_csv(header=False, index=False)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(body)\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_3(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    update_method: str = \"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    is_index: bool = False,  # index after uploading\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "\n",
    "    \"\"\"commit will close the upload session, upload_id.  this request defines how the data will be loaded into Adrenaline, update_method\n",
    "    has optional flag for indexing dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/commit\"\n",
    "\n",
    "    body = {\"index\": is_index, \"action\": update_method}\n",
    "\n",
    "    if partition_tag:\n",
    "\n",
    "        body.update(\n",
    "            {\n",
    "                \"action\": \"APPEND\",\n",
    "                #  'dataTag': restate_data_tag or data_tag,\n",
    "                #  'appendId': 'latest' if (restate_data_tag or data_tag) else None,\n",
    "                \"dataTag\": partition_tag,\n",
    "                \"appendId\": \"latest\" if partition_tag else None,\n",
    "                \"index\": is_index,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"PUT\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=3, dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "ds_id = \"cbae0e0c-a92d-4a4c-8d0c-c9ccd38fe928\"\n",
    "\n",
    "# await get_schema(dataset_id= ds_id, auth=token_auth)\n",
    "\n",
    "df = pd.DataFrame([{\"col_a\": \"a\", \"col_b\": \"b\", \"col_c\": \"c\"}])\n",
    "\n",
    "\n",
    "s1_res = await upload_dataset_stage_1(\n",
    "    auth=token_auth, dataset_id=ds_id, partition_tag=None, debug_api=False\n",
    ")\n",
    "\n",
    "upload_id = s1_res.response.get(\"uploadId\")\n",
    "upload_id\n",
    "\n",
    "s2_res = await upload_dataset_stage_2_df(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    upload_df=df,\n",
    "    part_id=2,\n",
    "    debug_api=False,\n",
    ")\n",
    "\n",
    "\n",
    "s3_res = await upload_dataset_stage_3(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    update_method=\"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    is_index=True,  # index after uploading\n",
    ")\n",
    "\n",
    "s3_res.is_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def index_dataset(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"manually index a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes\"\n",
    "\n",
    "    body = {\"dataIds\": []}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        url=url,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def index_status(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    index_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"get the completion status of an index\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes/{index_id}/statuses\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"GET\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_list_partitions_body(limit=100, offset=0):\n",
    "    return {\n",
    "        \"paginationFields\": [\n",
    "            {\n",
    "                \"fieldName\": \"datecompleted\",\n",
    "                \"sortOrder\": \"DESC\",\n",
    "                \"filterValues\": {\"MIN\": None, \"MAX\": None},\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset,\n",
    "    }\n",
    "\n",
    "\n",
    "async def list_partitions(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    body: dict = None,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "):\n",
    "\n",
    "    body = body or generate_list_partitions_body()\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/list\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    def arr_fn(res) -> list[dict]:\n",
    "        return res.response\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        body=body,\n",
    "        offset_params_in_body=True,\n",
    "        offset_params=offset_params,\n",
    "        loop_until_end=True,\n",
    "        session=session,\n",
    "        debug_loop=debug_loop,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance\n",
    "        )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataId</th>\n",
       "      <th>partitionId</th>\n",
       "      <th>dateCompleted</th>\n",
       "      <th>rowCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>372</td>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>2023-01-24T14:27:21.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2023-01-24T14:27:21.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>2013-07-20</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355</td>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>2013-07-18</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataId partitionId                  dateCompleted  rowCount\n",
       "0     372  2013-07-02  2023-01-24T14:27:21.000+00:00         1\n",
       "1     373  2013-07-01  2023-01-24T14:27:21.000+00:00         1\n",
       "2     354  2013-07-20  2023-01-24T14:27:20.000+00:00         1\n",
       "3     355  2013-07-19  2023-01-24T14:27:20.000+00:00         1\n",
       "4     356  2013-07-18  2023-01-24T14:27:20.000+00:00         1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "dataset_id = \"d2b21660-4ba8-400c-badf-aeef5a9abae1\"\n",
    "\n",
    "res = await list_partitions(auth=token_auth, dataset_id=dataset_id)\n",
    "\n",
    "ds_partition_ls = res.response\n",
    "\n",
    "pd.DataFrame(ds_partition_ls[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_create_dataset_body(\n",
    "    dataset_name: str, dataset_type: str = \"API\", schema: dict = None\n",
    "):\n",
    "    schema = schema or {\n",
    "        \"columns\": [\n",
    "            {\"type\": \"STRING\", \"name\": \"Friend\"},\n",
    "            {\"type\": \"STRING\", \"name\": \"Attending\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"userDefinedType\": dataset_type,\n",
    "        \"dataSourceName\": dataset_name,\n",
    "        \"schema\": schema,\n",
    "    }\n",
    "\n",
    "\n",
    "async def create(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_name: str,\n",
    "    dataset_type: str = \"api\",\n",
    "    session: httpx.AsyncClient = None,\n",
    "    schema: dict = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "\n",
    "    body = generate_create_dataset_body(\n",
    "        dataset_name=dataset_name, dataset_type=dataset_type, schema=schema\n",
    "    )\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v2/datasources\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\", domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"]\n",
    ")\n",
    "\n",
    "# await create(dataset_name = 'hello world', dataset_type = 'api', auth = token_auth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def delete_partition_stage_1(auth: dmda.DomoAuth,\n",
    "                                   dataset_id: str,\n",
    "                                    dataset_partition_id: str,\n",
    "                                    debug_api: bool = False):\n",
    "# Delete partition has 3 stages\n",
    "# Stage 1. This marks the data version associated with the partition tag as deleted.  It does not delete the partition tag or remove the association between the partition tag and data version.  There should be no need to upload an empty file – step #3 will remove the data from Adrenaline.\n",
    "# update on 9/9/2022 based on the conversation with Greg Swensen\n",
    "    url = f'https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/tag/{dataset_partition_id}/data'\n",
    "\n",
    "    return await gd.get_data(\n",
    "       auth=auth,\n",
    "       method=\"DELETE\",\n",
    "       url=url,\n",
    "      debug_api=debug_api)\n",
    "# Stage 2. This will remove the partition association so that it doesn’t show up in the list call.  Technically, this is not required as a partition against a deleted data version will not count against the 400 partition limit, but as the current partitions api doesn’t make that clear, cleaning these up will make it much easier for you to manage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def delete_partition_stage_2(auth: dmda.DomoAuth,\n",
    "                                   dataset_id: str,\n",
    "                                   dataset_partition_id: str,\n",
    "                                   debug_api: bool = False):\n",
    "    url = f'https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/{dataset_partition_id}'\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"DELETE\",\n",
    "        url=url,\n",
    "\n",
    "       debug_api=debug_api\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}?deleteMethod=hard\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"DELETE\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

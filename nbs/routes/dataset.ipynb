{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Routes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: dataset_routes.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp routes.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "from typing import Optional, List\n",
    "from enum import Enum\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "import httpx\n",
    "\n",
    "import domolibrary.client.get_data as gd\n",
    "import domolibrary.client.ResponseGetData as rgd\n",
    "import domolibrary.client.DomoAuth as dmda\n",
    "import domolibrary.client.DomoError as de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class DatasetNotFoundError(de.DomoError):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_id,\n",
    "        domo_instance,\n",
    "        status=None,\n",
    "        parent_class=None,\n",
    "        function_name=None,\n",
    "    ):\n",
    "        message = f\"dataset - {dataset_id} not found\"\n",
    "\n",
    "        super().__init__(\n",
    "            message,\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "            function_name=function_name,\n",
    "            parent_class=parent_class,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class QueryRequestError(de.DomoError):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_id,\n",
    "        domo_instance,\n",
    "        sql,\n",
    "        status=None,\n",
    "        message=\"\",\n",
    "        parent_class=None,\n",
    "        function_name=None,\n",
    "    ):\n",
    "        message = f\"dataset - {dataset_id} received a bad request {message}.  Check your SQL \\n {sql}\"\n",
    "\n",
    "        super().__init__(\n",
    "            message,\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "            parent_class=parent_class,\n",
    "            function_name=function_name,\n",
    "        )\n",
    "\n",
    "\n",
    "# typically do not use\n",
    "async def query_dataset_public(\n",
    "    dev_auth: dmda.DomoDeveloperAuth,\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: httpx.AsyncClient,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    \"\"\"query for hitting public apis, requires client_id and secret authentication\"\"\"\n",
    "\n",
    "    url = f\"https://api.domo.com/v1/datasets/query/execute/{dataset_id}?IncludeHeaders=true\"\n",
    "\n",
    "    body = {\"sql\": sql}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=dev_auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "\n",
    "async def query_dataset_private(\n",
    "    auth: dmda.DomoAuth,  # DomoFullAuth or DomoTokenAuth\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    loop_until_end: bool = False,  # retrieve all available rows\n",
    "    limit=100,  # maximum rows to return per request.  refers to PAGINATION\n",
    "    skip=0,\n",
    "    maximum=100,  # equivalent to the LIMIT or TOP clause in SQL, the number of rows to return total\n",
    "    filter_pdp_policy_id_ls: List[int] = None,\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "    timeout: int = 10,\n",
    "    parent_class=None,\n",
    "    debug_num_stacks_to_drop=1,\n",
    "):\n",
    "    \"\"\"execute SQL queries against private APIs, requires DomoFullAuth or DomoTokenAuth\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/execute/{dataset_id}\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    # def body_fn(skip, limit):\n",
    "    #     return {\"sql\": f\"{sql} limit {limit} offset {skip}\"}\n",
    "\n",
    "    def body_fn(skip, limit, body=None):\n",
    "        body = {\"sql\": f\"{sql} limit {limit} offset {skip}\"}\n",
    "\n",
    "        if filter_pdp_policy_id_ls:\n",
    "            body.update(\n",
    "                {\n",
    "                    \"context\": {\n",
    "                        \"dataControlContext\": {\n",
    "                            \"filterGroupIds\": filter_pdp_policy_id_ls,\n",
    "                            \"previewPdp\": True,\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return body\n",
    "\n",
    "    def arr_fn(res) -> pd.DataFrame:\n",
    "        rows_ls = res.response.get(\"rows\")\n",
    "        columns_ls = res.response.get(\"columns\")\n",
    "        output = []\n",
    "        for row in rows_ls:\n",
    "            new_row = {}\n",
    "            for index, column in enumerate(columns_ls):\n",
    "                new_row[column] = row[index]\n",
    "            output.append(new_row)\n",
    "            # pd.DataFrame(data=res.response.get('rows'), columns=res.response.get('columns'))\n",
    "        return output\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        offset_params=offset_params,\n",
    "        limit=limit,\n",
    "        skip=skip,\n",
    "        maximum=maximum,\n",
    "        session=session,\n",
    "        body_fn=body_fn,\n",
    "        debug_api=debug_api,\n",
    "        debug_loop=debug_loop,\n",
    "        loop_until_end=loop_until_end,\n",
    "        timeout=timeout,\n",
    "        parent_class=parent_class,\n",
    "        debug_num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    if res.status == 400 and res.response == \"Bad Request\":\n",
    "        raise QueryRequestError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            sql=sql,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise QueryRequestError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            sql=sql,\n",
    "            message=res.response,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectID</th>\n",
       "      <th>url</th>\n",
       "      <th>Title</th>\n",
       "      <th>article</th>\n",
       "      <th>views</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>published_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000005034</td>\n",
       "      <td>https://domo-support.domo.com/s/article/360042...</td>\n",
       "      <td>Adding Scale Markers to Your Charts</td>\n",
       "      <td>IntroDomo provides the ability to set scale ma...</td>\n",
       "      <td>50</td>\n",
       "      <td>2022-11-02T21:00:00</td>\n",
       "      <td>2022-11-02T21:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000004347</td>\n",
       "      <td>https://domo-support.domo.com/s/article/457779...</td>\n",
       "      <td>Accessing Goals Data</td>\n",
       "      <td>IntroIn Goals, you can see the overall status ...</td>\n",
       "      <td>23</td>\n",
       "      <td>2022-10-24T21:41:00</td>\n",
       "      <td>2022-10-24T22:39:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    objectID                                                url  \\\n",
       "0  000005034  https://domo-support.domo.com/s/article/360042...   \n",
       "1  000004347  https://domo-support.domo.com/s/article/457779...   \n",
       "\n",
       "                                 Title  \\\n",
       "0  Adding Scale Markers to Your Charts   \n",
       "1                 Accessing Goals Data   \n",
       "\n",
       "                                             article  views  \\\n",
       "0  IntroDomo provides the ability to set scale ma...     50   \n",
       "1  IntroIn Goals, you can see the overall status ...     23   \n",
       "\n",
       "            created_dt         published_dt  \n",
       "0  2022-11-02T21:00:00  2022-11-02T21:04:00  \n",
       "1  2022-10-24T21:41:00  2022-10-24T22:39:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "\n",
    "dataset_id = os.environ[\"DOJO_DATASET_ID\"]\n",
    "\n",
    "\n",
    "sql = f\"SELECT * FROM TABLE\"\n",
    "\n",
    "ds_res = await query_dataset_private(\n",
    "    dataset_id=dataset_id,\n",
    "    auth=token_auth,\n",
    "    sql=sql,\n",
    "    skip=0,\n",
    "    limit=1000,\n",
    "    filter_pdp_policy_id_ls=[1225, 1226],  # to apply pdp filter context\n",
    "    loop_until_end=True,\n",
    "    debug_api=False,\n",
    ")\n",
    "print(len(ds_res.response))\n",
    "pd.DataFrame(ds_res.response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_dataset_by_id(\n",
    "    dataset_id: str,  # dataset id from URL\n",
    "    auth: Optional[dmda.DomoAuth] = None,  # requires full authentication\n",
    "    debug_api: bool = False,  # for troubleshooting API request\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    parent_class: str = None,\n",
    "    debug_num_stacks_to_drop=1,\n",
    ") -> rgd.ResponseGetData:  # returns metadata about a dataset\n",
    "    \"\"\"retrieve dataset metadata\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"GET\",\n",
    "        debug_api=debug_api,\n",
    "        session=session,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n",
      "ðŸ›‘  DatasetNotFoundError ðŸ›‘ - function: get_dataset_by_id || dataset - 123 not found || status 404 || error at domo-community\n"
     ]
    }
   ],
   "source": [
    "#| eval : false\n",
    "try:\n",
    "    token_auth = dmda.DomoTokenAuth(\n",
    "        domo_instance=\"domo-community\",\n",
    "        domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    )\n",
    "\n",
    "    await get_dataset_by_id(dataset_id=123, auth=token_auth)\n",
    "\n",
    "except DatasetNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>displayType</th>\n",
       "      <th>dataProviderType</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>owner</th>\n",
       "      <th>status</th>\n",
       "      <th>created</th>\n",
       "      <th>lastTouched</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>...</th>\n",
       "      <th>adcSource</th>\n",
       "      <th>cloudId</th>\n",
       "      <th>cloudName</th>\n",
       "      <th>permissions</th>\n",
       "      <th>hidden</th>\n",
       "      <th>tags</th>\n",
       "      <th>scheduleActive</th>\n",
       "      <th>cardCount</th>\n",
       "      <th>cryoStatus</th>\n",
       "      <th>cloudEngine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04c1574e-c8be-4721-9846-c6ffa491144b</td>\n",
       "      <td>domo-jupyterdata</td>\n",
       "      <td>domo-jupyterdata</td>\n",
       "      <td>Jupyter</td>\n",
       "      <td>domo_kbs</td>\n",
       "      <td>{'id': '1893952720', 'name': 'Jae Wilson1', 't...</td>\n",
       "      <td>SUCCESS</td>\n",
       "      <td>1668379680000</td>\n",
       "      <td>1711216181000</td>\n",
       "      <td>1668385822045</td>\n",
       "      <td>...</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>domo</td>\n",
       "      <td>Domo</td>\n",
       "      <td>READ_WRITE_DELETE_SHARE_ADMIN</td>\n",
       "      <td>False</td>\n",
       "      <td>[\"developer_documentation\",\"hackercore\"]</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>ADRENALINE</td>\n",
       "      <td>domo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id       displayType  dataProviderType  \\\n",
       "0  04c1574e-c8be-4721-9846-c6ffa491144b  domo-jupyterdata  domo-jupyterdata   \n",
       "\n",
       "      type      name                                              owner  \\\n",
       "0  Jupyter  domo_kbs  {'id': '1893952720', 'name': 'Jae Wilson1', 't...   \n",
       "\n",
       "    status        created    lastTouched    lastUpdated  ...  adcSource  \\\n",
       "0  SUCCESS  1668379680000  1711216181000  1668385822045  ...     DIRECT   \n",
       "\n",
       "   cloudId cloudName                    permissions hidden  \\\n",
       "0     domo      Domo  READ_WRITE_DELETE_SHARE_ADMIN  False   \n",
       "\n",
       "                                       tags  scheduleActive  cardCount  \\\n",
       "0  [\"developer_documentation\",\"hackercore\"]            True          2   \n",
       "\n",
       "   cryoStatus  cloudEngine  \n",
       "0  ADRENALINE         domo  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval : false\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "ds_res = await get_dataset_by_id(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth\n",
    ")\n",
    "pd.DataFrame([ds_res.response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_schema(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    debug_num_stacks_to_drop=1,\n",
    "    parent_class=None,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"retrieve the schema for a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/schema/indexed?includeHidden=false\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"GET\",\n",
    "        debug_api=debug_api,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of get_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>visible</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>objectID</td>\n",
       "      <td>objectID</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>url</td>\n",
       "      <td>url</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title</td>\n",
       "      <td>Title</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article</td>\n",
       "      <td>article</td>\n",
       "      <td>STRING</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>views</td>\n",
       "      <td>views</td>\n",
       "      <td>LONG</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>created_dt</td>\n",
       "      <td>created_dt</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>published_dt</td>\n",
       "      <td>published_dt</td>\n",
       "      <td>DATETIME</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name            id      type  visible  order\n",
       "0      objectID      objectID    STRING     True      0\n",
       "1           url           url    STRING     True      0\n",
       "2         Title         Title    STRING     True      0\n",
       "3       article       article    STRING     True      0\n",
       "4         views         views      LONG     True      0\n",
       "5    created_dt    created_dt  DATETIME     True      0\n",
       "6  published_dt  published_dt  DATETIME     True      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "res = await get_schema(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth)\n",
    "# retrieve schema from response\n",
    "pd.DataFrame(res.response.get(\"tables\")[0].get(\"columns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def alter_schema(\n",
    "    auth: dmda.DomoAuth,\n",
    "    schema_obj: dict,\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    parent_class: str = None,\n",
    "    debug_num_stacks_to_drop: int = 1,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"retrieve the schema for a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v2/datasources/{dataset_id}/schemas\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=schema_obj,\n",
    "        debug_api=debug_api,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseGetData(status=200, response={'schemaId': 3}, is_success=True, parent_class=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "schema_res = await get_schema(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth)\n",
    "\n",
    "schema_obj = schema_res.response[\"tables\"][0]\n",
    "\n",
    "await alter_schema(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth, schema_obj=schema_obj\n",
    ")\n",
    "\n",
    "## must index dataset after alter schema\n",
    "# await index_dataset(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def set_dataset_tags(\n",
    "    auth: dmda.DomoFullAuth,\n",
    "    tag_ls: List[str],  # complete list of tags for dataset\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    return_raw: bool = False,\n",
    "    parent_class: str = None,\n",
    "    debug_num_stacks_to_drop: int = 1,\n",
    "):\n",
    "    \"\"\"REPLACE tags on this dataset with a new list\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/ui/v3/datasources/{dataset_id}/tags\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        debug_api=debug_api,\n",
    "        body=tag_ls,\n",
    "        session=session,\n",
    "        return_raw=return_raw,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if return_raw:\n",
    "        return res\n",
    "\n",
    "    if res.status == 200:\n",
    "        res.set_response(\n",
    "            response=f'Dataset {dataset_id} tags updated to [{ \", \".join(tag_ls) }]'\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseGetData(status=200, response='Dataset 04c1574e-c8be-4721-9846-c6ffa491144b tags updated to [hackercore, developer_documentation]', is_success=True, parent_class=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval : false\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    domo_instance=\"domo-community\",\n",
    ")\n",
    "\n",
    "tag_ls = [\"hackercore\", \"developer_documentation\"]\n",
    "\n",
    "await set_dataset_tags(\n",
    "    auth=token_auth,\n",
    "    tag_ls=tag_ls,\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"],\n",
    "    debug_api=False,\n",
    "    return_raw=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "#### overview\n",
    "\n",
    "In the URL, parts refers to the multi-part API and is unrelated to the partitions concept. The multi-part API was designed to allow sending multiple streams of Data into a data_version simultaneously.\n",
    "\n",
    "In stage 1, the values passed in the Body will be superseded by values in the COMMIT (stage 3), so best practices is to not populate values here.\n",
    "\n",
    "The response includes an uploadId, which must be stored and passed to the URL of the subsequent upload request (stages 2 and 3).\n",
    "\n",
    "#### url params\n",
    "\n",
    "The dataTag parameter allows users to UPDATE or REPLACE a datatag (partition)\n",
    "\n",
    "NOTE: restateDataTag is largely deprecated // exists for backward compatibility\n",
    "\n",
    "#### body params\n",
    "\n",
    "The appendId parameter accepts \"latest\" or \"None\"\n",
    "\n",
    "latest will APPEND the data version to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class UploadDataError(de.DomoError):\n",
    "    \"\"\"raise if unable to upload data to Domo\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, stage_num: int, dataset_id: str, status, message, domo_instance: str\n",
    "    ):\n",
    "        message = f\"error uploading data during Stage { stage_num} - {message}\"\n",
    "\n",
    "        super().__init__(\n",
    "            entity_id=dataset_id,\n",
    "            message=message,\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_1(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    "    return_raw: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"preps dataset for upload by creating an upload_id (upload session key) pass to stage 2 as a parameter\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads\"\n",
    "\n",
    "    # base body assumes no paritioning\n",
    "    body = {\"action\": None, \"appendId\": None}\n",
    "\n",
    "    params = None\n",
    "\n",
    "    if partition_tag:\n",
    "        # params = {'dataTag': restate_data_tag or data_tag} # deprecated\n",
    "        params = {\"dataTag\": partition_tag}\n",
    "        body.update({\"appendId\": \"latest\"})\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=1,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    if return_raw:\n",
    "        return res\n",
    "\n",
    "    upload_id = res.response.get(\"uploadId\")\n",
    "\n",
    "    if not upload_id:\n",
    "        raise UploadDataError(\n",
    "            stage_num=1,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=\"no upload_id\",\n",
    "        )\n",
    "\n",
    "    res.response = upload_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n",
      "adjusting num_stacks_to_drop, consider revising `get_traceback` call\n",
      "{'stack_length': 16, 'module_index': 12, 'num_stacks_to_drop_passed': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseGetData(status=200, response=1000, is_success=True, parent_class=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "dataset_id = \"b102e530-6472-4cc3-b420-d5ab3792fdf9\"\n",
    "partition_key = \"2023-04-27\"\n",
    "\n",
    "await upload_dataset_stage_1(\n",
    "    auth=token_auth, dataset_id=dataset_id, partition_tag=partition_key, debug_api=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_2_file(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    data_file: Optional[io.TextIOWrapper] = None,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    part_id: str = 2,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = data_file\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def upload_dataset_stage_2_df(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    upload_df: pd.DataFrame,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    part_id: str = 2,  # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = upload_df.to_csv(header=False, index=False)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(body)\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_3(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    update_method: str = \"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    is_index: bool = False,  # index after uploading\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"commit will close the upload session, upload_id.  this request defines how the data will be loaded into Adrenaline, update_method\n",
    "    has optional flag for indexing dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/commit\"\n",
    "\n",
    "    body = {\"index\": is_index, \"action\": update_method}\n",
    "\n",
    "    if partition_tag:\n",
    "        body.update(\n",
    "            {\n",
    "                \"action\": \"APPEND\",\n",
    "                #  'dataTag': restate_data_tag or data_tag,\n",
    "                #  'appendId': 'latest' if (restate_data_tag or data_tag) else None,\n",
    "                \"dataTag\": partition_tag,\n",
    "                \"appendId\": \"latest\" if partition_tag else None,\n",
    "                \"index\": is_index,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"PUT\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=3,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n",
      "adjusting num_stacks_to_drop, consider revising `get_traceback` call\n",
      "{'stack_length': 16, 'module_index': 12, 'num_stacks_to_drop_passed': 3}\n",
      "adjusting num_stacks_to_drop, consider revising `get_traceback` call\n",
      "{'stack_length': 16, 'module_index': 12, 'num_stacks_to_drop_passed': 3}\n",
      "adjusting num_stacks_to_drop, consider revising `get_traceback` call\n",
      "{'stack_length': 16, 'module_index': 12, 'num_stacks_to_drop_passed': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval : false\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "ds_id = \"cbae0e0c-a92d-4a4c-8d0c-c9ccd38fe928\"\n",
    "\n",
    "# await get_schema(dataset_id= ds_id, auth=token_auth)\n",
    "\n",
    "df = pd.DataFrame([{\"col_a\": \"a\", \"col_b\": \"b\", \"col_c\": \"c\"}])\n",
    "\n",
    "\n",
    "s1_res = await upload_dataset_stage_1(\n",
    "    auth=token_auth, dataset_id=ds_id, partition_tag=None, debug_api=False\n",
    ")\n",
    "\n",
    "upload_id = s1_res.response\n",
    "upload_id\n",
    "\n",
    "s2_res = await upload_dataset_stage_2_df(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    upload_df=df,\n",
    "    part_id=2,\n",
    "    debug_api=False,\n",
    ")\n",
    "\n",
    "\n",
    "s3_res = await upload_dataset_stage_3(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    update_method=\"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    is_index=True,  # index after uploading\n",
    ")\n",
    "\n",
    "s3_res.is_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def index_dataset(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"manually index a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes\"\n",
    "\n",
    "    body = {\"dataIds\": []}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        url=url,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def index_status(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    index_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"get the completion status of an index\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes/{index_id}/statuses\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"GET\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_list_partitions_body(limit=100, offset=0):\n",
    "    return {\n",
    "        \"paginationFields\": [\n",
    "            {\n",
    "                \"fieldName\": \"datecompleted\",\n",
    "                \"sortOrder\": \"DESC\",\n",
    "                \"filterValues\": {\"MIN\": None, \"MAX\": None},\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset,\n",
    "    }\n",
    "\n",
    "\n",
    "async def list_partitions(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    body: dict = None,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "):\n",
    "    body = body or generate_list_partitions_body()\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/list\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    def arr_fn(res) -> list[dict]:\n",
    "        return res.response\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        body=body,\n",
    "        offset_params_in_body=True,\n",
    "        offset_params=offset_params,\n",
    "        loop_until_end=True,\n",
    "        session=session,\n",
    "        debug_loop=debug_loop,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance, status=res.status\n",
    "        )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataId</th>\n",
       "      <th>partitionId</th>\n",
       "      <th>dateCompleted</th>\n",
       "      <th>rowCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>372</td>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>2023-01-24T14:27:21.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2023-01-24T14:27:21.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>2013-07-20</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355</td>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>356</td>\n",
       "      <td>2013-07-18</td>\n",
       "      <td>2023-01-24T14:27:20.000+00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataId partitionId                  dateCompleted  rowCount\n",
       "0     372  2013-07-02  2023-01-24T14:27:21.000+00:00         1\n",
       "1     373  2013-07-01  2023-01-24T14:27:21.000+00:00         1\n",
       "2     354  2013-07-20  2023-01-24T14:27:20.000+00:00         1\n",
       "3     355  2013-07-19  2023-01-24T14:27:20.000+00:00         1\n",
       "4     356  2013-07-18  2023-01-24T14:27:20.000+00:00         1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "dataset_id = \"d2b21660-4ba8-400c-badf-aeef5a9abae1\"\n",
    "\n",
    "res = await list_partitions(auth=token_auth, dataset_id=dataset_id)\n",
    "\n",
    "ds_partition_ls = res.response\n",
    "\n",
    "pd.DataFrame(ds_partition_ls[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_create_dataset_body(\n",
    "    dataset_name: str, dataset_type: str = \"API\", schema: dict = None\n",
    "):\n",
    "    schema = schema or {\n",
    "        \"columns\": [\n",
    "            {\"type\": \"STRING\", \"name\": \"Friend\"},\n",
    "            {\"type\": \"STRING\", \"name\": \"Attending\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"userDefinedType\": dataset_type,\n",
    "        \"dataSourceName\": dataset_name,\n",
    "        \"schema\": schema,\n",
    "    }\n",
    "\n",
    "\n",
    "async def create(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_name: str,\n",
    "    dataset_type: str = \"api\",\n",
    "    session: httpx.AsyncClient = None,\n",
    "    schema: dict = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    body = generate_create_dataset_body(\n",
    "        dataset_name=dataset_name, dataset_type=dataset_type, schema=schema\n",
    "    )\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v2/datasources\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "# await create(dataset_name = 'hello world', dataset_type = 'api', auth = token_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete_partition_stage_1(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    dataset_partition_id: str,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    # Delete partition has 3 stages\n",
    "    # Stage 1. This marks the data version associated with the partition tag as deleted.  It does not delete the partition tag or remove the association between the partition tag and data version.  There should be no need to upload an empty file â€“ step #3 will remove the data from Adrenaline.\n",
    "    # update on 9/9/2022 based on the conversation with Greg Swensen\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/tag/{dataset_partition_id}/data\"\n",
    "\n",
    "    return await gd.get_data(auth=auth, method=\"DELETE\", url=url, debug_api=debug_api)\n",
    "\n",
    "\n",
    "# Stage 2. This will remove the partition association so that it doesnâ€™t show up in the list call.  Technically, this is not required as a partition against a deleted data version will not count against the 400 partition limit, but as the current partitions api doesnâ€™t make that clear, cleaning these up will make it much easier for you to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete_partition_stage_2(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    dataset_partition_id: str,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/{dataset_partition_id}\"\n",
    "\n",
    "    return await gd.get_data(auth=auth, method=\"DELETE\", url=url, debug_api=debug_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}?deleteMethod=hard\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"DELETE\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ShareDataset_AccessLevelEnum(Enum):\n",
    "    CO_OWNER = \"CO_OWNER\"\n",
    "    CAN_EDIT = \"CAN_EDIT\"\n",
    "    CAN_SHARE = \"CAN_SHARE\"\n",
    "\n",
    "\n",
    "def generate_share_dataset_payload(\n",
    "    entity_type,  # USER or GROUP\n",
    "    entity_id,\n",
    "    access_level: ShareDataset_AccessLevelEnum = ShareDataset_AccessLevelEnum.CAN_SHARE,\n",
    "    is_send_email: bool = False,\n",
    "):\n",
    "    return {\n",
    "        \"permissions\": [\n",
    "            {\"type\": entity_type, \"id\": entity_id, \"accessLevel\": access_level.value}\n",
    "        ],\n",
    "        \"sendEmail\": is_send_email,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ShareDataset_Error(de.DomoError):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_id,\n",
    "        status,\n",
    "        response,\n",
    "        domo_instance,\n",
    "        parent_class=None,\n",
    "        function_name=None,\n",
    "    ):\n",
    "        message = f\"error sharing dataset {dataset_id} - {response}\"\n",
    "\n",
    "        super().__init__(\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "            message=message,\n",
    "            parent_class=parent_class,\n",
    "            function_name=function_name,\n",
    "        )\n",
    "\n",
    "\n",
    "async def share_dataset(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    body: dict,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api=False,\n",
    "    parent_class=None,\n",
    "    debug_num_stacks_to_drop=1,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/share\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise ShareDataset_Error(\n",
    "            dataset_id=dataset_id,\n",
    "            status=res.status,\n",
    "            response=res.response,\n",
    "            domo_instance=auth.domo_instance,\n",
    "        )\n",
    "\n",
    "    update_user_ls = [f\"{user['type']} - {user['id']}\" for user in body[\"permissions\"]]\n",
    "\n",
    "    res.response = (\n",
    "        f\"updated access list { ', '.join(update_user_ls)} added to {dataset_id}\"\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n",
      "ResponseGetData(status=200, response='updated access list USER - 663516735 added to d2b21660-4ba8-400c-badf-aeef5a9abae1', is_success=True, parent_class=None)\n"
     ]
    }
   ],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "\n",
    "body = generate_share_dataset_payload(\n",
    "    entity_type=\"USER\",\n",
    "    entity_id=os.environ[\"DOMO_DOJO_USER_ID\"],\n",
    "    #    access_level=ShareDataset_EntityTypes_Enum.CO_OWNER\n",
    ")\n",
    "\n",
    "dataset_id = \"d2b21660-4ba8-400c-badf-aeef5a9abae1\"\n",
    "\n",
    "try:\n",
    "    print(await share_dataset(dataset_id=dataset_id, body=body, auth=token_auth))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Routes\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: dataset_routes.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp routes.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "from typing import Optional, List\n",
    "from enum import Enum\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "import httpx\n",
    "\n",
    "import domolibrary.client.get_data as gd\n",
    "import domolibrary.client.ResponseGetData as rgd\n",
    "import domolibrary.client.DomoAuth as dmda\n",
    "import domolibrary.client.DomoError as de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class DatasetNotFoundError(de.DomoError):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_id,\n",
    "        domo_instance,\n",
    "        status=None,\n",
    "        parent_class=None,\n",
    "        function_name=None,\n",
    "    ):\n",
    "        message = f\"dataset - {dataset_id} not found\"\n",
    "\n",
    "        super().__init__(\n",
    "            message,\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "            function_name=function_name,\n",
    "            parent_class=parent_class,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class QueryRequestError(de.DomoError):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_id,\n",
    "        domo_instance,\n",
    "        sql,\n",
    "        status=None,\n",
    "        message=\"\",\n",
    "        parent_class=None,\n",
    "        function_name=None,\n",
    "    ):\n",
    "        message = f\"dataset - {dataset_id} received a bad request {message}.  Check your SQL \\n {sql}\"\n",
    "\n",
    "        super().__init__(\n",
    "            message,\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "            parent_class=parent_class,\n",
    "            function_name=function_name,\n",
    "        )\n",
    "\n",
    "\n",
    "# typically do not use\n",
    "async def query_dataset_public(\n",
    "    dev_auth: dmda.DomoDeveloperAuth,\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: httpx.AsyncClient,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    \"\"\"query for hitting public apis, requires client_id and secret authentication\"\"\"\n",
    "\n",
    "    url = f\"https://api.domo.com/v1/datasets/query/execute/{dataset_id}?IncludeHeaders=true\"\n",
    "\n",
    "    body = {\"sql\": sql}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=dev_auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "\n",
    "async def query_dataset_private(\n",
    "    auth: dmda.DomoAuth,  # DomoFullAuth or DomoTokenAuth\n",
    "    dataset_id: str,\n",
    "    sql: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    loop_until_end: bool = False,  # retrieve all available rows\n",
    "    limit=100,  # maximum rows to return per request.  refers to PAGINATION\n",
    "    skip=0,\n",
    "    maximum=100,  # equivalent to the LIMIT or TOP clause in SQL, the number of rows to return total\n",
    "    filter_pdp_policy_id_ls: List[int] = None,\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "    timeout: int = 10,\n",
    "    parent_class=None,\n",
    "    debug_num_stacks_to_drop=1,\n",
    "):\n",
    "    \"\"\"execute SQL queries against private APIs, requires DomoFullAuth or DomoTokenAuth\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/execute/{dataset_id}\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    # def body_fn(skip, limit):\n",
    "    #     return {\"sql\": f\"{sql} limit {limit} offset {skip}\"}\n",
    "\n",
    "    def body_fn(skip, limit, body=None):\n",
    "        body = {\"sql\": f\"{sql} limit {limit} offset {skip}\"}\n",
    "\n",
    "        if filter_pdp_policy_id_ls:\n",
    "            body.update(\n",
    "                {\n",
    "                    \"context\": {\n",
    "                        \"dataControlContext\": {\n",
    "                            \"filterGroupIds\": filter_pdp_policy_id_ls,\n",
    "                            \"previewPdp\": True,\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return body\n",
    "\n",
    "    def arr_fn(res) -> pd.DataFrame:\n",
    "        rows_ls = res.response.get(\"rows\")\n",
    "        columns_ls = res.response.get(\"columns\")\n",
    "        output = []\n",
    "        for row in rows_ls:\n",
    "            new_row = {}\n",
    "            for index, column in enumerate(columns_ls):\n",
    "                new_row[column] = row[index]\n",
    "            output.append(new_row)\n",
    "            # pd.DataFrame(data=res.response.get('rows'), columns=res.response.get('columns'))\n",
    "        return output\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        offset_params=offset_params,\n",
    "        limit=limit,\n",
    "        skip=skip,\n",
    "        maximum=maximum,\n",
    "        session=session,\n",
    "        body_fn=body_fn,\n",
    "        debug_api=debug_api,\n",
    "        debug_loop=debug_loop,\n",
    "        loop_until_end=loop_until_end,\n",
    "        timeout=timeout,\n",
    "        parent_class=parent_class,\n",
    "        debug_num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    if res.status == 400 and res.response == \"Bad Request\":\n",
    "        raise QueryRequestError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            sql=sql,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise QueryRequestError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            sql=sql,\n",
    "            message=res.response,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectID</th>\n",
       "      <th>url</th>\n",
       "      <th>Title</th>\n",
       "      <th>article</th>\n",
       "      <th>views</th>\n",
       "      <th>created_dt</th>\n",
       "      <th>published_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000005034</td>\n",
       "      <td>https://domo-support.domo.com/s/article/360042...</td>\n",
       "      <td>Adding Scale Markers to Your Charts</td>\n",
       "      <td>IntroDomo provides the ability to set scale ma...</td>\n",
       "      <td>50</td>\n",
       "      <td>2022-11-02T21:00:00</td>\n",
       "      <td>2022-11-02T21:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000004347</td>\n",
       "      <td>https://domo-support.domo.com/s/article/457779...</td>\n",
       "      <td>Accessing Goals Data</td>\n",
       "      <td>IntroIn Goals, you can see the overall status ...</td>\n",
       "      <td>23</td>\n",
       "      <td>2022-10-24T21:41:00</td>\n",
       "      <td>2022-10-24T22:39:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    objectID                                                url  \\\n",
       "0  000005034  https://domo-support.domo.com/s/article/360042...   \n",
       "1  000004347  https://domo-support.domo.com/s/article/457779...   \n",
       "\n",
       "                                 Title  \\\n",
       "0  Adding Scale Markers to Your Charts   \n",
       "1                 Accessing Goals Data   \n",
       "\n",
       "                                             article  views  \\\n",
       "0  IntroDomo provides the ability to set scale ma...     50   \n",
       "1  IntroIn Goals, you can see the overall status ...     23   \n",
       "\n",
       "            created_dt         published_dt  \n",
       "0  2022-11-02T21:00:00  2022-11-02T21:04:00  \n",
       "1  2022-10-24T21:41:00  2022-10-24T22:39:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "\n",
    "dataset_id = os.environ[\"DOJO_DATASET_ID\"]\n",
    "\n",
    "\n",
    "sql = f\"SELECT * FROM TABLE\"\n",
    "\n",
    "ds_res = await query_dataset_private(\n",
    "    dataset_id=dataset_id,\n",
    "    auth=token_auth,\n",
    "    sql=sql,\n",
    "    skip=0,\n",
    "    limit=1000,\n",
    "    filter_pdp_policy_id_ls=[1225, 1226],  # to apply pdp filter context\n",
    "    loop_until_end=True,\n",
    "    debug_api=False,\n",
    ")\n",
    "print(len(ds_res.response))\n",
    "pd.DataFrame(ds_res.response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_dataset_by_id(\n",
    "    dataset_id: str,  # dataset id from URL\n",
    "    auth: Optional[dmda.DomoAuth] = None,  # requires full authentication\n",
    "    debug_api: bool = False,  # for troubleshooting API request\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    parent_class: str = None,\n",
    "    debug_num_stacks_to_drop=1,\n",
    ") -> rgd.ResponseGetData:  # returns metadata about a dataset\n",
    "    \"\"\"retrieve dataset metadata\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"GET\",\n",
    "        debug_api=debug_api,\n",
    "        session=session,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            parent_class=parent_class,\n",
    "            function_name=res.traceback_details.function_name,\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n",
      "🛑  DatasetNotFoundError 🛑 - function: get_dataset_by_id || dataset - 123 not found || status 404 || error at domo-community\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    token_auth = dmda.DomoTokenAuth(\n",
    "        domo_instance=\"domo-community\",\n",
    "        domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    )\n",
    "\n",
    "    await get_dataset_by_id(dataset_id=123, auth=token_auth)\n",
    "\n",
    "except DatasetNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning this token has not been validated by who_am_i, run get_auth_token first\n"
     ]
    },
    {
     "ename": "ConnectTimeout",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:373\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 373\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpcore/_async/connection_pool.py:216\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpcore/_async/connection_pool.py:196\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpcore/_async/connection.py:99\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpcore/_async/connection.py:76\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(request)\n\u001b[1;32m     78\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpcore/_async/connection.py:154\u001b[0m, in \u001b[0;36mAsyncHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_tls\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 154\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mstart_tls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    155\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpcore/_backends/anyio.py:66\u001b[0m, in \u001b[0;36mAnyIOStream.start_tls\u001b[0;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[1;32m     62\u001b[0m exc_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ConnectTimeout,\n\u001b[1;32m     64\u001b[0m     anyio\u001b[38;5;241m.\u001b[39mBrokenResourceError: ConnectError,\n\u001b[1;32m     65\u001b[0m }\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m token_auth \u001b[38;5;241m=\u001b[39m dmda\u001b[38;5;241m.\u001b[39mDomoTokenAuth(\n\u001b[1;32m      5\u001b[0m     domo_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdomo-community\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     domo_access_token\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOMO_DOJO_ACCESS_TOKEN\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m ds_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_dataset_by_id(\n\u001b[1;32m     10\u001b[0m     dataset_id\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOJO_DATASET_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m], auth\u001b[38;5;241m=\u001b[39mtoken_auth\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame([ds_res\u001b[38;5;241m.\u001b[39mresponse])\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mget_dataset_by_id\u001b[0;34m(dataset_id, auth, debug_api, session, parent_class, debug_num_stacks_to_drop)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"retrieve dataset metadata\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauth\u001b[38;5;241m.\u001b[39mdomo_instance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.domo.com/api/data/v3/datasources/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m gd\u001b[38;5;241m.\u001b[39mget_data(\n\u001b[1;32m     15\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m     16\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m     17\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     debug_api\u001b[38;5;241m=\u001b[39mdebug_api,\n\u001b[1;32m     19\u001b[0m     session\u001b[38;5;241m=\u001b[39msession,\n\u001b[1;32m     20\u001b[0m     parent_class\u001b[38;5;241m=\u001b[39mparent_class,\n\u001b[1;32m     21\u001b[0m     num_stacks_to_drop\u001b[38;5;241m=\u001b[39mdebug_num_stacks_to_drop,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Found\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[1;32m     26\u001b[0m         dataset_id\u001b[38;5;241m=\u001b[39mdataset_id,\n\u001b[1;32m     27\u001b[0m         domo_instance\u001b[38;5;241m=\u001b[39mauth\u001b[38;5;241m.\u001b[39mdomo_instance,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         function_name\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mtraceback_details\u001b[38;5;241m.\u001b[39mfunction_name,\n\u001b[1;32m     31\u001b[0m     )\n",
      "File \u001b[0;32m/home/GitHub/domo_library/domolibrary/client/get_data.py:172\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(url, method, auth, content_type, headers, body, params, debug_api, session, return_raw, is_follow_redirects, timeout, parent_class, num_stacks_to_drop, debug_traceback, is_verify)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🐛 debugging get_data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auth \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mtoken:\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m auth\u001b[38;5;241m.\u001b[39mget_auth_token()\n\u001b[1;32m    174\u001b[0m headers \u001b[38;5;241m=\u001b[39m create_headers(auth\u001b[38;5;241m=\u001b[39mauth, content_type\u001b[38;5;241m=\u001b[39mcontent_type, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    176\u001b[0m session, is_close_session \u001b[38;5;241m=\u001b[39m create_httpx_session(\n\u001b[1;32m    177\u001b[0m     session\u001b[38;5;241m=\u001b[39msession, is_verify\u001b[38;5;241m=\u001b[39mis_verify\n\u001b[1;32m    178\u001b[0m )\n",
      "File \u001b[0;32m/home/GitHub/domo_library/domolibrary/client/DomoAuth.py:237\u001b[0m, in \u001b[0;36mDomoTokenAuth.get_auth_token\u001b[0;34m(self, session, debug_api)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_auth_token\u001b[39m(\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28mself\u001b[39m, session: Optional[httpx\u001b[38;5;241m.\u001b[39mAsyncClient] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, debug_api: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    231\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    updates internal attributes\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    having an access_token assumes pre-authenticaiton\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwho_am_i()\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m res\u001b[38;5;241m.\u001b[39mis_success\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_valid_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/home/GitHub/domo_library/domolibrary/client/DomoAuth.py:189\u001b[0m, in \u001b[0;36m_DomoTokenAuth_Required.who_am_i\u001b[0;34m(self, debug_api, session)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwho_am_i\u001b[39m(\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m, debug_api: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, session: httpx\u001b[38;5;241m.\u001b[39mAsyncClient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    185\u001b[0m ):\n\u001b[1;32m    187\u001b[0m     auth_header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauth_header \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_auth_header()\n\u001b[0;32m--> 189\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auth_routes\u001b[38;5;241m.\u001b[39mwho_am_i(\n\u001b[1;32m    190\u001b[0m         domo_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomo_instance,\n\u001b[1;32m    191\u001b[0m         auth_header\u001b[38;5;241m=\u001b[39mauth_header,\n\u001b[1;32m    192\u001b[0m         parent_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/home/GitHub/domo_library/domolibrary/routes/auth.py:291\u001b[0m, in \u001b[0;36mwho_am_i\u001b[0;34m(auth_header, domo_instance, session, parent_class, debug_num_stacks_to_drop, debug_api, return_raw)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug_api:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mprint\u001b[39m(url, auth_header)\n\u001b[0;32m--> 291\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, headers\u001b[38;5;241m=\u001b[39mauth_header, url\u001b[38;5;241m=\u001b[39murl)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_close_session:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m session\u001b[38;5;241m.\u001b[39maclose()\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_client.py:1574\u001b[0m, in \u001b[0;36mAsyncClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m   1559\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m   1561\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m   1562\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m   1563\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1572\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m   1573\u001b[0m )\n\u001b[0;32m-> 1574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(request, auth\u001b[38;5;241m=\u001b[39mauth, follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects)\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_client.py:1661\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m   1653\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m   1657\u001b[0m )\n\u001b[1;32m   1659\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m-> 1661\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m   1662\u001b[0m     request,\n\u001b[1;32m   1663\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1664\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1665\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   1666\u001b[0m )\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_client.py:1689\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1686\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auth_flow\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m   1690\u001b[0m         request,\n\u001b[1;32m   1691\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1692\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m   1693\u001b[0m     )\n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1695\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_client.py:1726\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1724\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[0;32m-> 1726\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1728\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_client.py:1763\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1758\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1759\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1760\u001b[0m     )\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1763\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n\u001b[1;32m   1766\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:372\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n\u001b[1;32m    360\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    361\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    362\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    370\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    371\u001b[0m )\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m    373\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    151\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m/home/GitHub/domo_library/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "ds_res = await get_dataset_by_id(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth\n",
    ")\n",
    "pd.DataFrame([ds_res.response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def get_schema(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    debug_num_stacks_to_drop=1,\n",
    "    parent_class=None,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"retrieve the schema for a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/schema/indexed?includeHidden=false\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"GET\",\n",
    "        debug_api=debug_api,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of get_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "res = await get_schema(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth)\n",
    "# retrieve schema from response\n",
    "pd.DataFrame(res.response.get(\"tables\")[0].get(\"columns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def alter_schema(\n",
    "    auth: dmda.DomoAuth,\n",
    "    schema_obj: dict,\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    parent_class: str = None,\n",
    "    debug_num_stacks_to_drop: int = 1,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"retrieve the schema for a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v2/datasources/{dataset_id}/schemas\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=schema_obj,\n",
    "        debug_api=debug_api,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "schema_res = await get_schema(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth)\n",
    "\n",
    "schema_obj = schema_res.response[\"tables\"][0]\n",
    "\n",
    "await alter_schema(\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth, schema_obj=schema_obj\n",
    ")\n",
    "\n",
    "## must index dataset after alter schema\n",
    "# await index_dataset(dataset_id=os.environ[\"DOJO_DATASET_ID\"], auth=token_auth )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def set_dataset_tags(\n",
    "    auth: dmda.DomoFullAuth,\n",
    "    tag_ls: List[str],  # complete list of tags for dataset\n",
    "    dataset_id: str,\n",
    "    debug_api: bool = False,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    return_raw: bool = False,\n",
    "    parent_class: str = None,\n",
    "    debug_num_stacks_to_drop: int = 1,\n",
    "):\n",
    "    \"\"\"REPLACE tags on this dataset with a new list\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/ui/v3/datasources/{dataset_id}/tags\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        debug_api=debug_api,\n",
    "        body=tag_ls,\n",
    "        session=session,\n",
    "        return_raw=return_raw,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if return_raw:\n",
    "        return res\n",
    "\n",
    "    if res.status == 200:\n",
    "        res.set_response(\n",
    "            response=f'Dataset {dataset_id} tags updated to [{ \", \".join(tag_ls) }]'\n",
    "        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    "    domo_instance=\"domo-community\",\n",
    ")\n",
    "\n",
    "tag_ls = [\"hackercore\", \"developer_documentation\"]\n",
    "\n",
    "await set_dataset_tags(\n",
    "    auth=token_auth,\n",
    "    tag_ls=tag_ls,\n",
    "    dataset_id=os.environ[\"DOJO_DATASET_ID\"],\n",
    "    debug_api=False,\n",
    "    return_raw=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "#### overview\n",
    "\n",
    "In the URL, parts refers to the multi-part API and is unrelated to the partitions concept. The multi-part API was designed to allow sending multiple streams of Data into a data_version simultaneously.\n",
    "\n",
    "In stage 1, the values passed in the Body will be superseded by values in the COMMIT (stage 3), so best practices is to not populate values here.\n",
    "\n",
    "The response includes an uploadId, which must be stored and passed to the URL of the subsequent upload request (stages 2 and 3).\n",
    "\n",
    "#### url params\n",
    "\n",
    "The dataTag parameter allows users to UPDATE or REPLACE a datatag (partition)\n",
    "\n",
    "NOTE: restateDataTag is largely deprecated // exists for backward compatibility\n",
    "\n",
    "#### body params\n",
    "\n",
    "The appendId parameter accepts \"latest\" or \"None\"\n",
    "\n",
    "latest will APPEND the data version to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class UploadDataError(de.DomoError):\n",
    "    \"\"\"raise if unable to upload data to Domo\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, stage_num: int, dataset_id: str, status, message, domo_instance: str\n",
    "    ):\n",
    "        message = f\"error uploading data during Stage { stage_num} - {message}\"\n",
    "\n",
    "        super().__init__(\n",
    "            entity_id=dataset_id,\n",
    "            message=message,\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_1(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    "    return_raw: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"preps dataset for upload by creating an upload_id (upload session key) pass to stage 2 as a parameter\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads\"\n",
    "\n",
    "    # base body assumes no paritioning\n",
    "    body = {\"action\": None, \"appendId\": None}\n",
    "\n",
    "    params = None\n",
    "\n",
    "    if partition_tag:\n",
    "        # params = {'dataTag': restate_data_tag or data_tag} # deprecated\n",
    "        params = {\"dataTag\": partition_tag}\n",
    "        body.update({\"appendId\": \"latest\"})\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        url=url,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=1,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    if return_raw:\n",
    "        return res\n",
    "\n",
    "    upload_id = res.response.get(\"uploadId\")\n",
    "\n",
    "    if not upload_id:\n",
    "        raise UploadDataError(\n",
    "            stage_num=1,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=\"no upload_id\",\n",
    "        )\n",
    "\n",
    "    res.response = upload_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "dataset_id = \"b102e530-6472-4cc3-b420-d5ab3792fdf9\"\n",
    "partition_key = \"2023-04-27\"\n",
    "\n",
    "await upload_dataset_stage_1(\n",
    "    auth=token_auth, dataset_id=dataset_id, partition_tag=partition_key, debug_api=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_2_file(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    data_file: Optional[io.TextIOWrapper] = None,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    part_id: str = 2,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = data_file\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def upload_dataset_stage_2_df(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    upload_df: pd.DataFrame,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    part_id: str = 2,  # only necessary if streaming multiple files into the same partition (multi-part upload)\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/parts/{part_id}\"\n",
    "\n",
    "    body = upload_df.to_csv(header=False, index=False)\n",
    "\n",
    "    # if debug:\n",
    "    #     print(body)\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        url=url,\n",
    "        method=\"PUT\",\n",
    "        auth=auth,\n",
    "        content_type=\"text/csv\",\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=2,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "    res.part_id = part_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_dataset_stage_3(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    upload_id: str,  # must originate from  a stage_1 upload response\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    update_method: str = \"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    #  restate_data_tag: str = None, # deprecated\n",
    "    partition_tag: str = None,  # synonymous with data_tag\n",
    "    is_index: bool = False,  # index after uploading\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"commit will close the upload session, upload_id.  this request defines how the data will be loaded into Adrenaline, update_method\n",
    "    has optional flag for indexing dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/uploads/{upload_id}/commit\"\n",
    "\n",
    "    body = {\"index\": is_index, \"action\": update_method}\n",
    "\n",
    "    if partition_tag:\n",
    "        body.update(\n",
    "            {\n",
    "                \"action\": \"APPEND\",\n",
    "                #  'dataTag': restate_data_tag or data_tag,\n",
    "                #  'appendId': 'latest' if (restate_data_tag or data_tag) else None,\n",
    "                \"dataTag\": partition_tag,\n",
    "                \"appendId\": \"latest\" if partition_tag else None,\n",
    "                \"index\": is_index,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"PUT\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise UploadDataError(\n",
    "            stage_num=3,\n",
    "            dataset_id=dataset_id,\n",
    "            domo_instance=auth.domo_instance,\n",
    "            status=res.status,\n",
    "            message=res.response,\n",
    "        )\n",
    "\n",
    "    res.upload_id = upload_id\n",
    "    res.dataset_id = dataset_id\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "ds_id = \"cbae0e0c-a92d-4a4c-8d0c-c9ccd38fe928\"\n",
    "\n",
    "# await get_schema(dataset_id= ds_id, auth=token_auth)\n",
    "\n",
    "df = pd.DataFrame([{\"col_a\": \"a\", \"col_b\": \"b\", \"col_c\": \"c\"}])\n",
    "\n",
    "\n",
    "s1_res = await upload_dataset_stage_1(\n",
    "    auth=token_auth, dataset_id=ds_id, partition_tag=None, debug_api=False\n",
    ")\n",
    "\n",
    "upload_id = s1_res.response\n",
    "upload_id\n",
    "\n",
    "s2_res = await upload_dataset_stage_2_df(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    upload_df=df,\n",
    "    part_id=2,\n",
    "    debug_api=False,\n",
    ")\n",
    "\n",
    "\n",
    "s3_res = await upload_dataset_stage_3(\n",
    "    auth=token_auth,\n",
    "    dataset_id=ds_id,\n",
    "    upload_id=upload_id,\n",
    "    update_method=\"REPLACE\",  # accepts REPLACE or APPEND\n",
    "    is_index=True,  # index after uploading\n",
    ")\n",
    "\n",
    "s3_res.is_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def index_dataset(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"manually index a dataset\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes\"\n",
    "\n",
    "    body = {\"dataIds\": []}\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        body=body,\n",
    "        url=url,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def index_status(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    index_id: str,\n",
    "    session: Optional[httpx.AsyncClient] = None,\n",
    "    debug_api: bool = False,\n",
    ") -> rgd.ResponseGetData:\n",
    "    \"\"\"get the completion status of an index\"\"\"\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/indexes/{index_id}/statuses\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"GET\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_list_partitions_body(limit=100, offset=0):\n",
    "    return {\n",
    "        \"paginationFields\": [\n",
    "            {\n",
    "                \"fieldName\": \"datecompleted\",\n",
    "                \"sortOrder\": \"DESC\",\n",
    "                \"filterValues\": {\"MIN\": None, \"MAX\": None},\n",
    "            }\n",
    "        ],\n",
    "        \"limit\": limit,\n",
    "        \"offset\": offset,\n",
    "    }\n",
    "\n",
    "\n",
    "async def list_partitions(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    body: dict = None,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "    debug_loop: bool = False,\n",
    "):\n",
    "    body = body or generate_list_partitions_body()\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/list\"\n",
    "\n",
    "    offset_params = {\n",
    "        \"offset\": \"offset\",\n",
    "        \"limit\": \"limit\",\n",
    "    }\n",
    "\n",
    "    def arr_fn(res) -> list[dict]:\n",
    "        return res.response\n",
    "\n",
    "    res = await gd.looper(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        arr_fn=arr_fn,\n",
    "        body=body,\n",
    "        offset_params_in_body=True,\n",
    "        offset_params=offset_params,\n",
    "        loop_until_end=True,\n",
    "        session=session,\n",
    "        debug_loop=debug_loop,\n",
    "        debug_api=debug_api,\n",
    "    )\n",
    "\n",
    "    if res.status == 404 and res.response == \"Not Found\":\n",
    "        raise DatasetNotFoundError(\n",
    "            dataset_id=dataset_id, domo_instance=auth.domo_instance, status=res.status\n",
    "        )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "dataset_id = \"d2b21660-4ba8-400c-badf-aeef5a9abae1\"\n",
    "\n",
    "res = await list_partitions(auth=token_auth, dataset_id=dataset_id)\n",
    "\n",
    "ds_partition_ls = res.response\n",
    "\n",
    "pd.DataFrame(ds_partition_ls[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def generate_create_dataset_body(\n",
    "    dataset_name: str, dataset_type: str = \"API\", schema: dict = None\n",
    "):\n",
    "    schema = schema or {\n",
    "        \"columns\": [\n",
    "            {\"type\": \"STRING\", \"name\": \"Friend\"},\n",
    "            {\"type\": \"STRING\", \"name\": \"Attending\"},\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"userDefinedType\": dataset_type,\n",
    "        \"dataSourceName\": dataset_name,\n",
    "        \"schema\": schema,\n",
    "    }\n",
    "\n",
    "\n",
    "async def create(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_name: str,\n",
    "    dataset_type: str = \"api\",\n",
    "    session: httpx.AsyncClient = None,\n",
    "    schema: dict = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    body = generate_create_dataset_body(\n",
    "        dataset_name=dataset_name, dataset_type=dataset_type, schema=schema\n",
    "    )\n",
    "\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v2/datasources\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "# await create(dataset_name = 'hello world', dataset_type = 'api', auth = token_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete_partition_stage_1(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    dataset_partition_id: str,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    # Delete partition has 3 stages\n",
    "    # Stage 1. This marks the data version associated with the partition tag as deleted.  It does not delete the partition tag or remove the association between the partition tag and data version.  There should be no need to upload an empty file – step #3 will remove the data from Adrenaline.\n",
    "    # update on 9/9/2022 based on the conversation with Greg Swensen\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/tag/{dataset_partition_id}/data\"\n",
    "\n",
    "    return await gd.get_data(auth=auth, method=\"DELETE\", url=url, debug_api=debug_api)\n",
    "\n",
    "\n",
    "# Stage 2. This will remove the partition association so that it doesn’t show up in the list call.  Technically, this is not required as a partition against a deleted data version will not count against the 400 partition limit, but as the current partitions api doesn’t make that clear, cleaning these up will make it much easier for you to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete_partition_stage_2(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    dataset_partition_id: str,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/query/v1/datasources/{dataset_id}/partition/{dataset_partition_id}\"\n",
    "\n",
    "    return await gd.get_data(auth=auth, method=\"DELETE\", url=url, debug_api=debug_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def delete(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}?deleteMethod=hard\"\n",
    "\n",
    "    return await gd.get_data(\n",
    "        auth=auth, method=\"DELETE\", url=url, session=session, debug_api=debug_api\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ShareDataset_AccessLevelEnum(Enum):\n",
    "    CO_OWNER = \"CO_OWNER\"\n",
    "    CAN_EDIT = \"CAN_EDIT\"\n",
    "    CAN_SHARE = \"CAN_SHARE\"\n",
    "\n",
    "\n",
    "def generate_share_dataset_payload(\n",
    "    entity_type,  # USER or GROUP\n",
    "    entity_id,\n",
    "    access_level: ShareDataset_AccessLevelEnum = ShareDataset_AccessLevelEnum.CAN_SHARE,\n",
    "    is_send_email: bool = False,\n",
    "):\n",
    "    return {\n",
    "        \"permissions\": [\n",
    "            {\"type\": entity_type, \"id\": entity_id, \"accessLevel\": access_level.value}\n",
    "        ],\n",
    "        \"sendEmail\": is_send_email,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class ShareDataset_Error(de.DomoError):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_id,\n",
    "        status,\n",
    "        response,\n",
    "        domo_instance,\n",
    "        parent_class=None,\n",
    "        function_name=None,\n",
    "    ):\n",
    "        message = f\"error sharing dataset {dataset_id} - {response}\"\n",
    "\n",
    "        super().__init__(\n",
    "            status=status,\n",
    "            domo_instance=domo_instance,\n",
    "            message=message,\n",
    "            parent_class=parent_class,\n",
    "            function_name=function_name,\n",
    "        )\n",
    "\n",
    "\n",
    "async def share_dataset(\n",
    "    auth: dmda.DomoAuth,\n",
    "    dataset_id: str,\n",
    "    body: dict,\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api=False,\n",
    "    parent_class=None,\n",
    "    debug_num_stacks_to_drop=1,\n",
    "):\n",
    "    url = f\"https://{auth.domo_instance}.domo.com/api/data/v3/datasources/{dataset_id}/share\"\n",
    "\n",
    "    res = await gd.get_data(\n",
    "        auth=auth,\n",
    "        method=\"POST\",\n",
    "        url=url,\n",
    "        body=body,\n",
    "        session=session,\n",
    "        debug_api=debug_api,\n",
    "        parent_class=parent_class,\n",
    "        num_stacks_to_drop=debug_num_stacks_to_drop,\n",
    "    )\n",
    "\n",
    "    if not res.is_success:\n",
    "        raise ShareDataset_Error(\n",
    "            dataset_id=dataset_id,\n",
    "            status=res.status,\n",
    "            response=res.response,\n",
    "            domo_instance=auth.domo_instance,\n",
    "        )\n",
    "\n",
    "    update_user_ls = [f\"{user['type']} - {user['id']}\" for user in body[\"permissions\"]]\n",
    "\n",
    "    res.response = (\n",
    "        f\"updated access list { ', '.join(update_user_ls)} added to {dataset_id}\"\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval : false\n",
    "\n",
    "token_auth = dmda.DomoTokenAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_access_token=os.environ[\"DOMO_DOJO_ACCESS_TOKEN\"],\n",
    ")\n",
    "\n",
    "\n",
    "body = generate_share_dataset_payload(\n",
    "    entity_type=\"USER\",\n",
    "    entity_id=os.environ[\"DOMO_DOJO_USER_ID\"],\n",
    "    #    access_level=ShareDataset_EntityTypes_Enum.CO_OWNER\n",
    ")\n",
    "\n",
    "dataset_id = \"d2b21660-4ba8-400c-badf-aeef5a9abae1\"\n",
    "\n",
    "try:\n",
    "    print(await share_dataset(dataset_id=dataset_id, body=body, auth=token_auth))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

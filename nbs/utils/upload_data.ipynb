{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: utils.upload_data.html\n",
    "title: Upload Data to Domo\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils.upload_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "\n",
    "import domolibrary.client.Logger as lc\n",
    "import domolibrary.client.DomoAuth as dmda\n",
    "import domolibrary.classes.DomoDataset as dmds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "async def loop_upload(\n",
    "    upload_df: pd.DataFrame,\n",
    "    consol_ds: dmds.DomoDataset,\n",
    "    partition_key: str,\n",
    "    upload_method: str,\n",
    "    logger: lc.Logger,\n",
    "    debug_api: bool = False,\n",
    "    debug_prn: bool = False,\n",
    "    debug_fn: bool = True,\n",
    "    max_retry: int = 2,\n",
    "    is_index: bool = False\n",
    "):\n",
    "    base_msg = f\"{partition_key} in {consol_ds.auth.domo_instance}\" if partition_key else f\"in {consol_ds.auth.domo_instance}\"\n",
    "\n",
    "    if debug_fn:\n",
    "        print(\n",
    "            f\"starting upload of {len(upload_df)} rows to {base_msg} with {max_retry} attempts\")\n",
    "\n",
    "    retry_attempt = 0\n",
    "    \n",
    "    res = None\n",
    "\n",
    "    while retry_attempt <= max_retry:\n",
    "        try:\n",
    "            retry_attempt += 1\n",
    "\n",
    "            if debug_fn:\n",
    "                print(f\"attempt {retry_attempt} for {base_msg}\")\n",
    "\n",
    "            res = await consol_ds.upload_data(\n",
    "                upload_df=upload_df,\n",
    "                upload_method=\"REPLACE\" if partition_key else upload_method,\n",
    "                partition_key=partition_key,\n",
    "                is_index=is_index,\n",
    "                debug_api=debug_api,\n",
    "                debug_prn=debug_prn,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            message = f\"âš ï¸ upload_data : unexpected error: {e} in {partition_key} during retry_attempt {retry_attempt}\"\n",
    "\n",
    "            logger.log_warning(message)\n",
    "            if debug_fn :\n",
    "                print(message)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "async def upload_data(\n",
    "    # instance where the data_fn function will execute against\n",
    "    data_fn,  # data function to execute\n",
    "    instance_auth: dmda.DomoAuth,  # instance to run the data function against\n",
    "    consol_ds: dmds.DomoDataset,  # dataset where data should be accumulated\n",
    "    # if partition key supplied, will replace existing partition\n",
    "    partition_key: str = None,\n",
    "    upload_method: str = 'REPLACE',\n",
    "    is_index: bool = False,  # index dataset\n",
    "    debug_prn: bool = False,\n",
    "    debug_fn: bool = True,\n",
    "    debug_api: bool = False,\n",
    "    logger: lc.Logger = None,\n",
    "    max_retry: int = 2  # number of times to attempt upload\n",
    "):\n",
    "    logger = logger or lc.Logger(app_name=\"upload_data\")\n",
    "\n",
    "    try:\n",
    "        message = f\"ðŸ starting {instance_auth.domo_instance} - {data_fn.__name__}\"\n",
    "        logger.log_info(message)\n",
    "        print(message)\n",
    "        \n",
    "        instance_session = httpx.AsyncClient()\n",
    "\n",
    "        upload_df = await data_fn(instance_auth, instance_session, debug_api=debug_api)\n",
    "\n",
    "        if upload_df is None or len(upload_df.index) == 0:\n",
    "            message = f\"no data to upload for {partition_key}: {consol_ds.id} in {consol_ds.auth.domo_instance}\"\n",
    "            logger.log_info(message)\n",
    "            print(message)\n",
    "            return None\n",
    "\n",
    "        res = await loop_upload(\n",
    "            upload_df=upload_df,\n",
    "            consol_ds=consol_ds,\n",
    "            partition_key=partition_key,\n",
    "            upload_method=upload_method,\n",
    "            debug_api=debug_api,\n",
    "            debug_prn=debug_prn,\n",
    "            debug_fn=debug_fn,\n",
    "            max_retry=max_retry,\n",
    "            logger=logger,\n",
    "            is_index=False\n",
    "        )\n",
    "\n",
    "        if res.is_success:\n",
    "            message = f\"ðŸš€ success upload of {partition_key} to {consol_ds.id} in {consol_ds.auth.domo_instance} in {data_fn.__name__}\"\n",
    "            logger.log_info(message)\n",
    "\n",
    "        else:\n",
    "            message = f\"ðŸ’£ upload_data successful status but failed to upload {partition_key} - {res.status} - {res.response} in {data_fn.__name__}\"\n",
    "            logger.log_error(message)\n",
    "        \n",
    "        print(message)\n",
    "        \n",
    "        return res\n",
    "\n",
    "    finally:\n",
    "        if is_index:\n",
    "\n",
    "            res = await consol_ds.index_dataset(debug_api=debug_api, session=instance_session)\n",
    "            if res.is_success:\n",
    "                message = f\"ðŸ¥« successfully indexed {consol_ds.name} in {consol_ds.auth.domo_instance}\"\n",
    "                logger.log_info(message)\n",
    "            else:\n",
    "                message = f\"ðŸ’€âš ï¸ failure to index {consol_ds.name} in {consol_ds.auth.domo_instance}\"\n",
    "                loger.log_error(message)\n",
    "            \n",
    "            print(message)\n",
    "\n",
    "        await instance_session.aclose()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of upload_data with loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ starting domo-dojo - data_fn\n",
      "starting upload of 360 rows to domo-dojo in domo-dojo with 2 attempts\n",
      "attempt 1 for domo-dojo in domo-dojo\n",
      "attempt 2 for domo-dojo in domo-dojo\n",
      "attempt 3 for domo-dojo in domo-dojo\n",
      "ðŸš€ success upload of domo-dojo to 44c5af30-ea04-49e4-9d7a-529afd223590 in domo-dojo in data_fn\n",
      "ðŸ¥« successfully indexed demo_instance_features in domo-dojo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseGetData(status=200, response={'dataSourceId': '44c5af30-ea04-49e4-9d7a-529afd223590', 'uploadId': 91, 'dataTag': 'domo-dojo', 'status': 'SUCCESS', 'size': {'rowCount': 360, 'columnCount': 7, 'numberOfBytes': 20535, 'partCount': 1}, 'indexing': {'requested': False}}, is_success=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import domolibrary.classes.DomoBootstrap as dmbsr\n",
    "import httpx\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "async def data_fn(\n",
    "    instance_auth: dmda.DomoFullAuth,  # this API requires full auth\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"function to call.  must return a dataframe.\"\"\"\n",
    "    try:\n",
    "        bsr = dmbsr.DomoBootstrap(auth=instance_auth)\n",
    "        instance_features = await bsr.get_features(debug_api=debug_api, session=session)\n",
    "\n",
    "        upload_df = pd.DataFrame(instance_features)\n",
    "        upload_df[\"instance\"] = instance_auth.domo_instance\n",
    "\n",
    "        return upload_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"getting data : unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "### get_auth\n",
    "full_auth = dmda.DomoFullAuth(\n",
    "    domo_instance=\"domo-dojo\",\n",
    "    domo_username=\"jae@onyxreporting.com\",\n",
    "    domo_password=os.environ[\"DOJO_PASSWORD\"],\n",
    ")\n",
    "\n",
    "# confirm retrieves token\n",
    "assert isinstance(await full_auth.get_auth_token(), str)\n",
    "\n",
    "ds_id = \"44c5af30-ea04-49e4-9d7a-529afd223590\"\n",
    "ds = await dmds.DomoDataset.get_from_id(dataset_id=ds_id, auth=full_auth)\n",
    "\n",
    "await upload_data(\n",
    "    instance_auth=full_auth,  # instance where the data_fn function will execute against\n",
    "    consol_ds=ds,\n",
    "    partition_key=full_auth.domo_instance,\n",
    "    data_fn=data_fn,\n",
    "    is_index=True,\n",
    "    debug_fn=True,\n",
    "    debug_api = False,\n",
    "    max_retry=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "async def upload_data_with_date(\n",
    "    instance_auth,\n",
    "    consol_auth,\n",
    "    data_fn,\n",
    "    consol_ds,\n",
    "    partition_date_col,\n",
    "    partition_delimiter,\n",
    "    start_date,\n",
    "    end_date,\n",
    "    debug: bool = False,\n",
    "    debug_prn: bool = False,\n",
    "):\n",
    "\n",
    "    instance_session = httpx.AsyncClient()\n",
    "\n",
    "    print(\n",
    "        f\"'ðŸŽ¬ upload_with_data: starting retrieval {start_date}, {end_date}, {instance_auth.domo_instance}\"\n",
    "    )\n",
    "\n",
    "    upload_df = await data_fn(\n",
    "        instance_auth=instance_auth,\n",
    "        session=instance_session,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        debug=debug,\n",
    "    )\n",
    "\n",
    "    await instance_session.aclose()\n",
    "\n",
    "    if not isinstance(upload_df, pd.DataFrame):\n",
    "        print(f\"ðŸ›‘ error no data returned {instance_auth.domo_instance}\")\n",
    "        print(upload_df)\n",
    "        return None\n",
    "\n",
    "    if debug_prn:\n",
    "        print(\n",
    "            f\"ðŸ§» upload_with_data: starting upload {len(upload_df)} rows for {instance_auth.domo_instance}\"\n",
    "        )\n",
    "\n",
    "    task = []\n",
    "\n",
    "    for index, partition_set in upload_df.drop_duplicates(\n",
    "        subset=[partition_date_col]\n",
    "    ).iterrows():\n",
    "        partition_date = partition_set[partition_date_col]\n",
    "\n",
    "        partition_key = (\n",
    "            f\"{instance_auth.domo_instance}{partition_delimiter}{str(partition_date)}\"\n",
    "        )\n",
    "\n",
    "        task.append(\n",
    "            consol_ds.upload_data(\n",
    "                upload_df=upload_df[(upload_df[partition_date_col] == partition_date)],\n",
    "                upload_method=\"REPLACE\",\n",
    "                partition_key=partition_key,\n",
    "                is_index=False,\n",
    "                debug_api=debug_api,\n",
    "                debug_prn=debug_prn,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    res = await asyncio.gather(*task)\n",
    "\n",
    "    if debug_prn:\n",
    "        print(\n",
    "            f\"ðŸŽ‰ upload_with_data : finished uploading {len(upload_df)} rows for {instance_auth.domo_instance}\"\n",
    "        )\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

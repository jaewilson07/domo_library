{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: utils.upload_data.html\n",
    "title: Upload Data to Domo\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils.upload_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "import httpx\n",
    "import pandas as pd\n",
    "\n",
    "# import asyncio\n",
    "\n",
    "import domolibrary.client.Logger as lc\n",
    "import domolibrary.client.DomoAuth as dmda\n",
    "import domolibrary.classes.DomoDataset as dmds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "async def loop_upload(\n",
    "    upload_df: pd.DataFrame,\n",
    "    consol_ds: dmds.DomoDataset,\n",
    "    partition_key: str,\n",
    "    upload_method: str,\n",
    "    logger: lc.Logger,\n",
    "    debug_api: bool = False,\n",
    "    debug_prn: bool = False,\n",
    "    debug_fn: bool = True,\n",
    "    max_retry: int = 2,\n",
    "    is_index: bool = False\n",
    "):\n",
    "    base_msg = f\"{partition_key} in {consol_ds.auth.domo_instance}\" if partition_key else f\"in {consol_ds.auth.domo_instance}\"\n",
    "\n",
    "    if debug_fn:\n",
    "        print(\n",
    "            f\"starting upload of {len(upload_df)} rows to {base_msg} with {max_retry} attempts\")\n",
    "\n",
    "    retry_attempt = 0\n",
    "    \n",
    "    res = None\n",
    "\n",
    "    while retry_attempt <= max_retry:\n",
    "        try:\n",
    "            retry_attempt += 1\n",
    "\n",
    "            if debug_fn:\n",
    "                print(f\"attempt {retry_attempt} for {base_msg}\")\n",
    "\n",
    "            res = await consol_ds.upload_data(\n",
    "                upload_df=upload_df,\n",
    "                upload_method=\"REPLACE\" if partition_key else upload_method,\n",
    "                partition_key=partition_key,\n",
    "                is_index=is_index,\n",
    "                debug_api=debug_api,\n",
    "                debug_prn=debug_prn,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            message = f\"⚠️ upload_data : unexpected error: {e} in {partition_key} during retry_attempt {retry_attempt}\"\n",
    "\n",
    "            logger.log_warning(message)\n",
    "            if debug_fn :\n",
    "                print(message)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "async def upload_data(\n",
    "    # instance where the data_fn function will execute against\n",
    "    data_fn,  # data function to execute\n",
    "    instance_auth: dmda.DomoAuth,  # instance to run the data function against\n",
    "    consol_ds: dmds.DomoDataset,  # dataset where data should be accumulated\n",
    "    # if partition key supplied, will replace existing partition\n",
    "    partition_key: str = None,\n",
    "    upload_method: str = 'REPLACE',\n",
    "    is_index: bool = False,  # index dataset\n",
    "    debug_prn: bool = False,\n",
    "    debug_fn: bool = True,\n",
    "    debug_api: bool = False,\n",
    "    logger: lc.Logger = None,\n",
    "    max_retry: int = 2  # number of times to attempt upload\n",
    "):\n",
    "    logger = logger or lc.Logger(app_name=\"upload_data\")\n",
    "\n",
    "    try:\n",
    "        message = f\"🏁 starting {instance_auth.domo_instance} - {data_fn.__name__}\"\n",
    "        logger.log_info(message)\n",
    "        print(message)\n",
    "        \n",
    "        instance_session = httpx.AsyncClient()\n",
    "\n",
    "        upload_df = await data_fn(instance_auth, instance_session, debug_api=debug_api)\n",
    "\n",
    "        if upload_df is None or len(upload_df.index) == 0:\n",
    "            message = f\"no data to upload for {partition_key}: {consol_ds.id} in {consol_ds.auth.domo_instance}\"\n",
    "            logger.log_info(message)\n",
    "            print(message)\n",
    "            return None\n",
    "        \n",
    "        if debug_prn:\n",
    "            print(upload_df[0:5])\n",
    "\n",
    "        res = await loop_upload(\n",
    "            upload_df=upload_df,\n",
    "            consol_ds=consol_ds,\n",
    "            partition_key=partition_key,\n",
    "            upload_method=upload_method,\n",
    "            debug_api=debug_api,\n",
    "            debug_prn=debug_prn,\n",
    "            debug_fn=debug_fn,\n",
    "            max_retry=max_retry,\n",
    "            logger=logger,\n",
    "            is_index=False\n",
    "        )\n",
    "\n",
    "        if res.is_success:\n",
    "            message = f\"🚀 success upload of {partition_key} to {consol_ds.id} in {consol_ds.auth.domo_instance} in {data_fn.__name__}\"\n",
    "            logger.log_info(message)\n",
    "\n",
    "        else:\n",
    "            message = f\"💣 upload_data successful status but failed to upload {partition_key} - {res.status} - {res.response} in {data_fn.__name__}\"\n",
    "            logger.log_error(message)\n",
    "        \n",
    "        print(message)\n",
    "        \n",
    "        return res\n",
    "\n",
    "    finally:\n",
    "        if is_index:\n",
    "\n",
    "            res = await consol_ds.index_dataset(debug_api=debug_api, session=instance_session)\n",
    "            if res.is_success:\n",
    "                message = f\"🥫 successfully indexed {consol_ds.name} in {consol_ds.auth.domo_instance}\"\n",
    "                logger.log_info(message)\n",
    "            else:\n",
    "                message = f\"💀⚠️ failure to index {consol_ds.name} in {consol_ds.auth.domo_instance}\"\n",
    "                logger.log_error(message)\n",
    "            \n",
    "            print(message)\n",
    "\n",
    "        await instance_session.aclose()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample implementation of upload_data with loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏁 starting domo-community - data_fn\n",
      "starting upload of 382 rows to domo-community in domo-community with 2 attempts\n",
      "attempt 1 for domo-community in domo-community\n",
      "attempt 2 for domo-community in domo-community\n",
      "attempt 3 for domo-community in domo-community\n",
      "🚀 success upload of domo-community to 44c5af30-ea04-49e4-9d7a-529afd223590 in domo-community in data_fn\n",
      "🥫 successfully indexed demo_instance_features in domo-community\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResponseGetData(status=200, response={'dataSourceId': '44c5af30-ea04-49e4-9d7a-529afd223590', 'uploadId': 509, 'dataTag': 'domo-community', 'status': 'SUCCESS', 'size': {'rowCount': 382, 'columnCount': 7, 'numberOfBytes': 23653, 'partCount': 1}, 'indexing': {'requested': False}}, is_success=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import domolibrary.classes.DomoBootstrap as dmbsr\n",
    "import httpx\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "async def data_fn(\n",
    "    instance_auth: dmda.DomoFullAuth,  # this API requires full auth\n",
    "    session: httpx.AsyncClient = None,\n",
    "    debug_api: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"function to call.  must return a dataframe.\"\"\"\n",
    "    try:\n",
    "        bsr = dmbsr.DomoBootstrap(auth=instance_auth)\n",
    "        instance_features = await bsr.get_features(debug_api=debug_api, session=session)\n",
    "\n",
    "        upload_df = pd.DataFrame(instance_features)\n",
    "        upload_df[\"instance\"] = instance_auth.domo_instance\n",
    "\n",
    "        return upload_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"getting data : unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "### get_auth\n",
    "full_auth = dmda.DomoFullAuth(\n",
    "    domo_instance=\"domo-community\",\n",
    "    domo_username=os.environ['DOMO_USERNAME'],\n",
    "    domo_password=os.environ[\"DOJO_PASSWORD\"],\n",
    ")\n",
    "\n",
    "# confirm retrieves token\n",
    "assert isinstance(await full_auth.get_auth_token(), str)\n",
    "\n",
    "ds_id = \"44c5af30-ea04-49e4-9d7a-529afd223590\"\n",
    "ds = await dmds.DomoDataset.get_from_id(dataset_id=ds_id, auth=full_auth)\n",
    "\n",
    "await upload_data(\n",
    "    instance_auth=full_auth,  # instance where the data_fn function will execute against\n",
    "    consol_ds=ds,\n",
    "    partition_key=full_auth.domo_instance,\n",
    "    data_fn=data_fn,\n",
    "    is_index=True,\n",
    "    debug_fn=True,\n",
    "    debug_api = False,\n",
    "    max_retry=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # | export\n",
    "# async def upload_data_with_date(\n",
    "#     instance_auth,\n",
    "#     data_fn,\n",
    "#     consol_ds,\n",
    "#     partition_date_col,\n",
    "#     partition_delimiter,\n",
    "#     start_date,\n",
    "#     end_date,\n",
    "#     debug_api: bool = False,\n",
    "#     debug_prn: bool = False,\n",
    "# ):\n",
    "\n",
    "#     instance_session = httpx.AsyncClient()\n",
    "\n",
    "#     print(\n",
    "#         f\"'🎬 upload_with_data: starting retrieval {start_date}, {end_date}, {instance_auth.domo_instance}\"\n",
    "#     )\n",
    "\n",
    "#     upload_df = await data_fn(\n",
    "#         instance_auth=instance_auth,\n",
    "#         session=instance_session,\n",
    "#         start_date=start_date,\n",
    "#         end_date=end_date,\n",
    "#         debug=debug,\n",
    "#     )\n",
    "\n",
    "#     await instance_session.aclose()\n",
    "\n",
    "#     if not isinstance(upload_df, pd.DataFrame):\n",
    "#         print(f\"🛑 error no data returned {instance_auth.domo_instance}\")\n",
    "#         print(upload_df)\n",
    "#         return None\n",
    "\n",
    "#     if debug_prn:\n",
    "#         print(\n",
    "#             f\"🧻 upload_with_data: starting upload {len(upload_df)} rows for {instance_auth.domo_instance}\"\n",
    "#         )\n",
    "\n",
    "#     task = []\n",
    "\n",
    "#     for index, partition_set in upload_df.drop_duplicates(\n",
    "#         subset=[partition_date_col]\n",
    "#     ).iterrows():\n",
    "#         partition_date = partition_set[partition_date_col]\n",
    "\n",
    "#         partition_key = (\n",
    "#             f\"{instance_auth.domo_instance}{partition_delimiter}{str(partition_date)}\"\n",
    "#         )\n",
    "\n",
    "#         task.append(\n",
    "#             consol_ds.upload_data(\n",
    "#                 upload_df=upload_df[(upload_df[partition_date_col] == partition_date)],\n",
    "#                 upload_method=\"REPLACE\",\n",
    "#                 partition_key=partition_key,\n",
    "#                 is_index=False,\n",
    "#                 debug_api=debug_api,\n",
    "#                 debug_prn=debug_prn,\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     res = await asyncio.gather(*task)\n",
    "\n",
    "#     if debug_prn:\n",
    "#         print(\n",
    "#             f\"🎉 upload_with_data : finished uploading {len(upload_df)} rows for {instance_auth.domo_instance}\"\n",
    "#         )\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b'\\xbf\\xbd\\xcb\\x11\\x17\\x1c\\xeaK\\x01\\xad\\xe1\\x82\\xfa\\xeb\\xbf\\x94\\xb0\\x0c \\x10\\x9e\\x88\\xad?\\xe7\\ny\\x81\\xd7\\xb9\\xe4\\xc8W\\xfc/\\x98\\xb1<\\xa2\\x02\\xe4\\xc30\\xb6sL\\x14\\x0c\\xcd\\xb9l\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00']\n",
      "Bad pipe message: %s [b'\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01']\n",
      "Bad pipe message: %s [b'<@\\x16\\x0fqr\\xacp\\xac\\x02\\x98$\\x06\\x8d\\xbda^=\\x00\\x00\\xa6\\xc0']\n",
      "Bad pipe message: %s [b'0\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e']\n",
      "Bad pipe message: %s [b\"\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\"]\n",
      "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
      "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\xad(2N\\x0e}\\xeb52N\\xf0[\\xc8P\\xbeK\\xd2\\xbc\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00']\n",
      "Bad pipe message: %s [b'\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01']\n",
      "Bad pipe message: %s [b'\\x89\\xd52\\xca\\xc8\\xd8\\x10\\x11.\\xb6K\\xb3(D\\xab|\\xc7}\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16']\n",
      "Bad pipe message: %s [b'\\x7f\\xd0\\x14\\xa9\\xea\\xabZ\\x16\\x90\\x95\\x9b\\xf3\\xf4/`\\xa6:q\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00', b'\\x11\\xc0\\x07\\xc0\\x16\\x00']\n",
      "Bad pipe message: %s [b'\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b']\n",
      "Bad pipe message: %s [b\"A\\xf2\\x83\\xe7\\xb7\\xb8\\x8d\\x1ep\\x9cB\\xb6\\xa6\\x9b\\xd3\\x11\\x85\\xff\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\"]\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
